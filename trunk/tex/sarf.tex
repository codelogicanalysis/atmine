%
% File naaclhlt2010.tex
%
% Contact: nasmith@cs.cmu.edu

\documentclass[11pt,letterpaper]{article}
\usepackage{arabtex}
\usepackage{naaclhlt2010}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{times}
\usepackage{caption}
\usepackage{epsfig}
\usepackage{subfigure}
\usepackage{color}
\usepackage{rotate}
\usepackage{rotating}
\usepackage{multirow}
\usepackage{amsthm}

\usepackage{relsize}
\usepackage{fancyvrb}
%\usepackage{times}
\usepackage{latexsym}
\usepackage[colorlinks=false]{hyperref}

\usepackage{utf8}
\setarab
\fullvocalize
%\transtrue
\arabtrue

\newcommand{\CharCodeIn}[1]{`\CodeIn{#1}'}
\newcommand{\CodeIn}[1]{{\small\texttt{#1}}}

\setlength\titlebox{6.5cm}    % Expanding the titlebox

%\title{Instructions for NAACL HLT 2010 Proceedings\Thanks{This...}}
\title{Case based Arabic Morphological Analysis with 
    Compositional Non-deterministic Automata }

%\author{ Jad Makhlouta \\
%  \And
%Hamza Harkous \\
%  American University of Beirut \\
%  {\tt \{jem04, hhh20, fz11\}@aub.edu.lb }
%  \And 
%  Fadi Zaraket 
%}

\date{}

\begin{document}
\maketitle

\begin{abstract}
Natural language processing uses morphological 
analysis to abstract and annotate text.
Often times, and in particular in the context
of the Arabic language, annotations resulting from 
an ongoing branch of morphological analysis may not be
appropriate for the case study at hand. 
In this paper we present Sarf, a case based morphological 
analyser for Arabic text. 
Sarf allows a case-based controller to control and refine
the state of the analysis on the fly. 
It uses compositional non-deterministic finite state machines 
to analyse a stream of text. 
Each alive machine corresponds to a valid analysis. 
Sarf uses concatenative analysis based on recursive affixes 
to better preserve part of speech information.
We automated the analysis of three books of Islamic
narrations (hadith) using Sarf where we
abstracted each book into a vector of complex structures.
Our results show high accuracy and efficiency compared to
state of the art analyzers. 
\end{abstract}

\section{Introduction}

Automated analysis of Arabic data sets, including texts, 
publications, records and digital media is essential
with the huge digital Arabic content available nowadays. 
Morphological analysis is key in current automated 
analysis techniques for Arabic text. 
Current morphological analyzers~\cite{Sughaiyer:04}
use concatenative analysis
to analyze an Arabic word and
consider its internal structure composed of several
{\em morphemes}. A morpheme can be a {\em stem}, or an {\em affix}.
An affix can be a {\em prefix, suffix, } or an {\em infix}.
The analysis of one word may lead to several possible
morphological solutions.
\vocalize
For instance the word \RL{'a.hmadH} 
may have two valid morphological analyses where in the first
\RL{'a} is a prefix and the word means ``I praise him'',
and in the second \RL{'a} is part of the stem 
\RL{'a.hmad} (a proper noun)
and the word means ``his Ahmad''.

\novocalize
The solutions suffer from accuracy due to inherent difficulties
of morphological analysis of the Arabic language. 
For example, it is common practice to write Arabic text
without short vowels. 
Arabic letters can also have up to four different shapes 
corresponding to their position in a word, i.e, begining of 
a word, middle of a word, end of word, and separated. 
This allows two consecutive words such as 
\RL{almdrsT}\RL{al_A}
to be visually recognizable
as two separate words \RL{al_A} and \RL{almdrsT} without 
the need of a delimiter such as a space in between. 
This specifically happens when the first word ends with
a non-connecting letter and is referred to as the ``run-o'' words
problem~\cite{Buckwalter:04}.
Such forms occur in text and greatly increase the
difficulty of tokenization.

Current morphological analyzers such as 
Buckwalter~\shortcite{Buckwalter:02},
Xerox~\cite{Beesley:01}, SAMA~\cite{Kulick:10},
and ElixirFM~\cite{Otakar:07} exist.
They take as input white space delimited tokens~\cite{Kulick:10},
consider them as words,
and enumerate all possible solutions. 
This exhaustive enumeration may hurt performance and may
not be necessary or appropriate
in some case studies as noted in~\cite{Maamouri:10}. 
Moreover, a white space delimited token may have 
more than one word.
Other morphological analyzers such as Amira~\cite{Diab:07,Benajiba:07},
MAGEAD~\cite{Habash:05}, and MADA+TOKAN~\cite{Habash:09} 
also use machine learning and support vector machines (SVM) 
to enhance the accuracy of the morphological analysis at the expense 
of perfomance.

We hypothesise that many NLP case studies need the 
morphological analyser to answer simple queries that do not need 
high complexity and accuracy at the low morphological analysis level 
and that can often compensate for tolerable inaccuracy at higher level. 
For example, if the query is interested in proper names and the 
prefix in question in the analysis can only connect to a verb, 
we can provide an answer without completing the analysis. 
%TODO A lso if a word such as \RL{wasiim} was name was ambiguous and we were looking for a sequence of names, then 
We find evidence to our hypothesis in~\cite{Maamouri:10} where the 
addition of a new corpus to the Arabic Tree Bank~\cite{Maamouri:04}
with features demanding resolution at an abstraction level
higher than the text itself
led to a refined analyzer~\cite{Kulick:10}.  
We also find evidence in~\cite{Habash:06} that different types of 
morphological analyses behave differently on the same case study. 
We strongly beleive and we find evidence in our results that a 
case-based controller intervening at every decision is necessary to 
guide, use, prune, and refine the morphological analysis.

\subsection{Sarf}
\label{sec:intro:sarf}

In this paper, we present Sarf, a {\em novel case-based efficient
morphological analyzer} that uses parallel compositional 
non-deterministic automata driven by a case based controller.
Each alive machine in Sarf represents a valid morphological analysis. 
Sarf keeps alive all possible analyses of the text and gives 
opportunity to the controller to intervene at every single input 
character. 
The decisions of the case-based controller can thus prune false 
positives early in the run. 
Each alive machine in Sarf takes as input one character at a time 
from a text stream. 
Sarf does not assume that the word at hand is a token and
performs tokenization on the fly based on morphological correctness.
To out knowledge, this is the first morphological analyzer that 
handles the ``run-on'' words problem. 

Sarf uses a {\em recursive} concatenative analysis with a novel 
refinement. 
Sarf introduces recursive affixes in order to
retain better part of speech information and enhance the 
efficiency of affix matching. 

We validate our hypothesis using a case study from the Islamic 
literature. 
A {\em hadith} is a narration related to the prophet Mohamad
through a {\em sanad} or a sequence of narrators. 
The authentication of a hadith higly depends on the credibility
of each of the narrators as reported in separate biography 
books. 
In this paper we consider the problem of automatically segmenting
a hadith book into narrations, then segmenting each narration into
its content or {\em matn} and its sanad.
We also would like to partition the sanad accurately into the 
separate narrators so that we can later look each one of them 
up in the biography books. 

The hadith case study is interesting for Sarf since the controller
considers most of the analyses where we have a concentration
of proper names in the text, and ignores most of the analyses as long 
as they are valid where we do not have proper names. 
The controller is also interested in a small subset of words 
that relate persons to each other such as \RL{bin} or ``the sun of''
or words that mean narrate such as \RL{qaal} or ``said''. 
With Sarf, we successfully automated the analysis of 
three books of Islamic narrations~\cite{IbnHanbal,AlTousi,AlKulayni}
and extracted from each one of them a vector of a three level deep
complex structure. 

%\subsection{Contributions}

We make the following key contributions. 
\begin{enumerate}
\item {\bf Case-based analysis:}  We deisgned and implemented
a case-based morphological analyzer where a case-based controller
machine controls and guides the analysis. 
\item {\bf Exhaustive analysis:} Since we have a case-based 
controller that can decide on the fly whether an analysis is 
accepted or not, we can afford to keep all valid analyses modulo
those pruned by the case controller. 
We do that using non-deterministic FSAs. 
\item {\bf Recursive affixes:}
We refine the concatenative analysis of 
Buckwalter~\shortcite{Buckwalter:02}  and use recursive affixes. 
This allowed Sarf to retain better compositional part of speech
tags.
\item {\bf Hadith case study:}
We evaluated Sarf using the hadith case study. We were able to
efficiently extract the sequence of narrators into a complex
data structure with three levels of hierarchy with high accuracy. 
\end{enumerate}



% does not have to be a subsection, 
%just to highlight it as an item we should not miss


% paper structure

%\section{Background}
% TODO: nondeterministic finite-state automata

\section{Related Work }
\label{sec:related}

The survey work in~\cite{Sughaiyer:04} discusses and compares
several morphological analyzers. 
Analyzers such as~\cite{Khoja:01,Darwish:02} 
target specific specific applications in the morphological 
analyzer itself or use a specific set of part of speech tags
as their reference.
Sarf differs in that it is a general and rich morphological 
analyzer that reports all possible solutions. 
It is case-based in the sense that a controller that drives
the morphological analyzers prunes these decisions. 
Up to our knowledge, Sarf is the only morphological analyzer
that addresses the ``run-on'' words problem. 

Sarf builds upon the lexicon of Buckwalter\shortcite{Buckwalter:02}.
It differs than Buckwalter where it defines a shorter list of affixes
and a longer list of affix compatibility rules to allow recursive 
affixes so that we can have prefix-prefix an suffix-suffix 
concatenations.
This allows Sarf to better maintain and propagate 
the part of speech information
tags associated with each prefix while these need to be highly 
redundant with Buckwalter and that may lead to consistency issues. 
Sarf keeps the possible analyses alive as a sequence corresponding
to the text. Buckwalter produces a set of solutions for each token 
and the several analysis threads of the whole text need to be 
generated as a product of the token solutions. 

Sarf is similar to Beesley~\shortcite{Beesley:01} in that it uses
finiste-state automata (FSA). 
Beesley reports that the number of the automata generated by a compiler
from Xerox rules is not controlled and also reports a difficulty to 
compose the FSAs into a single FSA framework. 
Sarf solves the problem with a non-deterministic composition of three
FSAs that are the prefix, stem, and suffix FSAs. 
With Sarf it is easy to control the FSAs with a user custom case 
controller, while with Beesley the effort requires recompiling the
Xerox rules.

Sarf is similar to The MADA+TOKAN toolkit in that it thinks of
the several valid morphological analyses as a richness that 
should be exploited at a higher abstract level rather than
an inaccuracy that should be corrected. 
Sarf differs in that it provides an interface for the 
case study to interfere in judging the analyses much earlier and
at a finer granularity level. 
Also in Sarf there is no need for a separate tokenizer such as
TOKAN as each alive automata carries with it the positions in 
text where a composition decision was made. 
The case-baded controller can build the trace when needed. 

%MAGEAD 
%Maamouri, Mohamed and \bgroup et al.\egroup },

We strongly feel that the refinemet of SAMA~\cite{Maamouri:10} 
is the closest to our approach. SAMA was refined to interact with
the ATB~\cite{Maamouri:04} project after the addition of a large 
new corpus. We find evidence in this decision that our hypothesis
about the utility of case-based analyzers. The refinements
that resulted in algorithmic changes in SAMA were done manually
and worked in integration with the ATB format only. 
In Sarf we propse a case-based controller approach that can modify 
the behaviour of the analyzer on the fly and that should interact
with the case study. In Sarf the analyzer remains general, and the 
case-based controller specializes the analyses.

The AMIRA~\cite{Diab:07} analyzer uses 
a language independent SVM based analysis. 
While the SVM analysis learns features from the text passed to the case
study, it does not make use of the type oh the query the 
case study targets in the text. 

Like ElixirFM~\cite{Otakar:07} Sarf builds on the lexicon
of the Buckwalter analyzer. 
We also use deterministic parsing with tries or our analysis 
to run the prefix, suffix and stem FSAs. 
We think that their inferential-realizational approach 
that is highly compatible with the Arabic linguistic 
description~\cite{Badawi:04}
can make benefit of many features unique to the Arabic language.
Sarf leaves implementing that to the case-based controller
since in many cases the abstraction needed may not need the 
text to be grammar correct.
We can compare the case-based controller in Sarf to a high level
component in the ElixirFM domain sepcific language. 

\section{Sarf}
\label{sec:sarf}

Sarf extends the lexicon of Buckwalter~\shortcite{Buckwalter:02} with 
proper names and location names extracted from different online 
sources~\footnote{\href{http://alasmaa.net/}{http://alasmaa.net/ }, 
\href{http://ar.wikipedia.org/}{http://ar.wikipedia.org/}}
as well as biblical sources~\footnote{Genesis 4:17-23; 5:1-32; 9:28-10:32; 11:10-32; 25:1-4, 12-18; 36:1-37:2; Exodus 6:14-25; Ruth 4:18-22; 1 Samuel 14:49-51; 1 Chronicles 1:1-9:44; 14:3-7; 24:1; 25:1-27:22; Nehemiah 12:8-26; Matthew 1:1-16; Luke 3:23-38}.

Sarf encodes the prefix, suffix and stem lexicons into 
three linear FSAs and uses a non-deterministic composition
of the three FSAs to compute all valid morphological analyses.
We first present a runing example of Sarf. 
The running example explains
how the non-deterministic composition works and 
illustrates how Sarf implements recursive affixes and
handles ``run-on'' words.
Then we discuss how Sarf builds and composes the different FSAs.

\subsection{Sarf example}
\label{sec:example}

\begin{figure*}[tb]
\center{
\resizebox{1.9\columnwidth}{!}
{ \input{psfigs/FSM.pstex_t}}
\caption{Example composition of the prefix, stem and suffix FSAs.}
\label{f:example}
}
\end{figure*}
% the FSMs for the three words

The compositional FSA diagram in Figure~\ref{f:example}
illustrates the operation of Sarf when parsing the
string \RL{al-lA`bwn}\RL{wsyl`b-h-aa}.
\footnote{ 
\RL{n}%
\RL{w}
\RL{b}
\RL{`}
\RL{a} 
\RL{l}
\RL{l}
\RL{a} %
\RL{a}
\RL{h}
\RL{b}
\RL{`}
\RL{l}
\RL{y}
\RL{s}
\RL{w}
in separate form to ease following the example
}
The square and circle legends are states of the FSA
and the directed edges are transitions driven by an input
character that matches the label of the edge. 
The square denotes an accept state, 
the circle denotes a regular state, and the reject states
are omitted for clarity. 
Figure~\ref{f:example}a represents the prefix FSA and 
Figures~\ref{f:example}b and~\ref{f:example}c represent the 
stem and suffix FSAs respectively. 
The symbol $\epsilon$ represents an empty string and is 
the source of non-determinism in this example. 

We start at the root square state in the prefix FSA
which is an accept state. 
The edge labeled $\epsilon$ that connects the prefix 
FSA to the stem FSA can transition from any accept state
in the prefix FSA to the root state in the stem FSA.
The edge that connects the stem FSA to the suffix FSA
follows the same behaviour. 

When there are two valid transitions such as \RL{w} 
and $\epsilon$ as is the start case, a non-deterministic 
FSA $\Phi$ spawns an exact copy of itself $\Psi$. FSA $\Phi$
makes one transition, and FSA $\Psi$ makes the other. 
Each of the FSAs now represent a valid analysis so far. 
When the FSA is at a state where the next input character
leads to a reject state, the FSA dies.
The reject states are omitted from Figure~\ref{f:example}
and are denoted by the abscence of the corresponding 
characters. 
In our examples, if we assume there were no stems that start 
with the letter \RL{w}, $\Psi$ will die then. 
In reality probably $\Psi$ will die when the input string
is at \RL{wsyl`}. 

Note that the prefix and affix FSAs allow recursive 
prefixes. For example, \RL{w} will result in an accept state
that transitions to the stem FSA. 
When \RL{s} follows, we move to another accept state in the 
prefix FSA corresponding to the suffix \RL{ws}. 
The same applies to the suffix FSA. 

Lets consider FSA $\Phi$ after it consumed \RL{wsy} 
and transitioned into the stem FSA root node. 
Now $\Phi$ will transition with \RL{l`b} to reach an accept 
state. 
Before moving with the letter \RL{b} to the accept state,
$\Phi$ needs to make sure that the stem \RL{l`b} is compatible
with the prefix \RL{wsy}. 
We do that by associating a category value for each accept state. 
We consider the value of the category as part of the state.
Thus each state shown in Figure~\ref{f:example} actually represents
more than one state. 
If the category of \RL{l`b} is compatible with the category of
\RL{wsy} then \RL{b} will move $\Phi$ to an accept state. 
Otherwise, it will move it to a regular or a reject state. 

Since $\Phi$ is now in an accept state in the stem FSA, it will
spawn $\Sigma$ that transitions into the root of the 
suffix FSA. When \RL{h} is consumed, $\Phi$ will die since 
there is no edge from the current state labeled with \RL{h}. 
Now $\Sigma$ represents a valid analysis and can proceed.

Note that $\Sigma$ can report a full word at any accept state
now by spawning a new automata using the $\epsilon$ transition
to the prefix FSA.
This is refined in Sarf to happen only with white space, delimiters, 
or non-connecting characters. 
We left that out in Figure~\ref{f:example} for clarity. 

Finally, The case-based controller can interfere at any point in the 
analysis to make a decision like ignoring an automata that 
is not interesting. 
It may also decide to correct the analysis of one automata
based on the decision of the others. 

\subsection{Recursive Affixes}
\label{sec:recaffix}

Morphological analysis partitions a given Arabic word
into a set of morphemes.
A morpheme is either an affix or a stem. 
We call two morphemes compatible if their concatenation
forms a legal morpheme. 
Buckwalter~\cite{Buckwalter:02} keeps separate lists 
of prefixes, suffixes and stems and assigns a category
to each morphemes. 
The relation between morphemes and categories is one 
to many. 

A compatibility rule is a pair of categories 
$\langle c_1, c_2\rangle$  stating that morphemes
with category $c_1$ can be concatenated with morphemes
of category $c_2$. 
Buckwalter keeps three lists $L_{ps}, L_{sx},$ and $L_{px}$ 
of compatibility rules relating
prefixes to stems, stems to suffixes, and prefixes to suffixes
respectively. 
Consider a string $s=\alpha\beta\gamma$ where $\alpha$ is 
a prefix, $\beta$ is a stem, and $\gamma$ is a suffix. 
The string $\alpha\beta\gamma$ partition of the string is a 
valid morphological analysis if  and only if we have
$\langle c(\alpha),c(\beta)\rangle \in L_{ps}$ and
$\langle c(\beta),c(\gamma)\rangle \in L_{sx}$ and
$\langle c(\alpha),c(\gamma)\rangle \in L_{px}$ where
$c()$ returns the category of the morpheme.

Many affixes are composed of other affixes. For example,
the prefix \RL{wsy} is composed of three other prefixes
namely \RL{w}, \RL{s}, and \RL{y}.
Moreover, the POS tag for \RL{wsy} is a concatenation
of the POS tags of each of the three morphemes. 
Keeping these morphemes separate in a list
is redundant and may produce consistency issues. 
We add two lists of compatibilty rules $L_{pp}$ and
$L_{xx}$ for prefix-prefix and suffix suffix compatibility
respectively.
This allows us to keep a shorter list of affixes. 
We need one more additional modification to accomodate 
a category for the morphemes accepted by the $L_{pp}$
and the $L_{xx}$ rules. For that we introduce the concept
of a {\em resulting category}. 
The resulting category in all practical cases
was the category of the second morpheme in the pair. 

\subsection{Affix Linear FSA}
\label{sec:affixFSA}

We analyzed the prefixes and suffixes of 
Buckwalter~\cite{Buckwalter:02}
and extracted our refined lists of recursives affixes.
We encoded the lists into a FSA similar to that
in Figure~\ref{f:example}(a) and Figure~\ref{f:example}(c).
The two FSAs are directed acyclic graphs. 
The abscence of cycles in these FSAs reduces the 
traversal of the affix FSAs to a linear traversal.
This is computationaly superior to the 
approach of Buckwalter where the analyzer considers
all possible substrings of the word in question
and looks it up in the affix tables. 

The prefix and suffix FSAs encode the $L_{pp}$ and
$L_{xx}$ compatibility lists.
An accept state in the FSA corresponds to the last character
of a prefix in the predix and suffix lists.
The accept states hold category state information as well
as POS and other tags.

\subsection{Stem Linear FSA}
\label{sec:stemFSA}

We built our stem lexicon using the stem lexicon of 
Buckwalter. 
We augmented the lexicon with a set of proper names and
a set of location names. 
We obtained the set of proper names from online 
and biblical sources. 

The stems share lots of substrings. We encoded them in
an efficient double array trie structure~\cite{Aoe:89}. 
The structure is also a linear FSA where the accept
states are the terminal nodes corresponding to the last 
letters in stems. 
This approach is superior to Buckwalter since again it is
a linear walk in the trie while with Buckwalter it is 
several hash lookups.

\subsection{Non-deterministic Composition of FSMs}
\label{sec:ndfsa}

The diagram in Figure~\ref{f:composition} shows an 
abstraction of the non-deterministic composition 
of the prefix, stem and suffix FSA. 
The circle represents regular states, the square
represents accept state and the triangle represents
reject states. 
Note that the concrete prefix, stem and suffix FSAs
are all linear and do not have cycles as discussed 
is Sections~\ref{sec:stemFSA} and~\ref{sec:affixFSA}.
The cycles are introduced in the abstract machine
for brevity and illustrative purposes.

\begin{figure*}[tb]
\center{
\resizebox{1.8\columnwidth}{!}
{ \input{psfigs/abstract_machine.pstex_t}}
\caption{An abstraction of the non-deterministic composition of 
    the prefix, stem and suffix FSAs.}
\label{f:composition}
}
\end{figure*}

The algorithm \CodeIn{NDSarf} below controls Sarf. 
It takes as input a text string $L$ and a case-based controller
$A$. 
It starts with one FSA $\Phi_1$ similar to the one in 
Figure~\ref{f:composition} and inserts it into a collection
of FSAs $M$. 
The algorithm reads a character $c$ at a time from $L$
and moves on all the machines in $M$. 
For each $\Phi$ in $M$ the algorithm checks whether
$\Phi$ is in an accept state or not. 

If $\Phi$ is in an accpet state and it is in the suffix
phase, then the algorithm checks whether it should report
a full word. 
This happens when $c$ is a white space or a delimiter, 
or when the last character leading to the current state
was a non-connecting character. 

In all cases, if $\Phi$ is in an accept state, 
it spawns another FSA $\Psi$ and adds it to $M$. 
If $c$ leads to a reject state, then $\Phi$ dies 
and we remove it from $M$. 
Otherwise, $\Phi$ transitions using the $c$ edge.
We invoke the controller $A$ after all the FSAs in $M$ 
have moved and allow it full access and control over
all FSAs in $M$. 

The arrows in Figure~\ref{f:composition} that transition
from prefix to stem, stem to suffix, and suffix to prefix
show the compatibility constraints as a condition for 
the transition.

\begin{table}[tb]
\centering
\begin{tabular} {p{6cm}}
\begin{Verbatim}[fontsize=\relsize{-1},
frame=topline,framesep=4mm,label=\fbox{NDSarf algorithm},
commandchars=\\\{\}, codes={\catcode`$=3\catcode`_=8}]
NDSarf(string $L$, Controller $A$) 
  FSAVec $M$; -- collection of FSA automata
  FSA $\Phi_1$;
  $M$.insert($\Phi_1$);
  foreach $c$ in $L$ \{
    foreach $\Phi$ in $M$ \{
      if ( $\Phi$.state.isAccept() ) \{
        if ($\Phi$.isSuffix())
          if ($c$.isWhite()) or 
            $A$.report();
          if ($\Phi$.lastChar().isNonConnecting())
            $A$.report();
        $\Psi$ = $\Phi$.clone();
        $M$.insert($\Psi$); \}

      if ( $\Phi$.isWalkable($c$) ) \{
        $\Phi$.transition($c$);
      \} else \{
        $M$.remove($\Phi$);
        $\Phi$.die();
      \} \} 
    $A$.control($M$, $c$); \}
\end{Verbatim}
\end{tabular}
\label{a:ndsarf}
\end{table}

\section{Islamic Literature Case Study}
\label{sec:islamic}

A hadith in Islamic literature is a narration from the prophet Mohamad
related by multiple narrators.
Establishing the authenticity of a hadith is an important task
in Islamic studies. 
%Several researchers~\cite{Hadithopaedia:08} attempted to automate 
%the analysis of the hadith literature. 
In this paper we use Sarf to sucessfully automate the
analysis of three books of hadith selected 
arbitrarily~\cite{IbnHanbal,AlKulayni,AlTousi}\footnote{We obtained
  the digitized books from online sources such as 
  \href{http://www.yasoob.com/}{http://www.yasoob.com/} and 
  \href{http://www.al-eman.com/}{http://www.al-eman.com/}. 
  Our understanding is that those books are historical documents with 
  public IP.}.

Our analysis accpets a book as a text stream input
and segements it into a vector of individual hadiths. 
We segment each hadith into two parts. The first part
is the sanad and it
contains the chain of narrators who related the hadith
to Mohamad. 
The second part is the matn and it constitutes the content
of the hadith. 
We are concerned in further exploring the sanad. 
In particular, we detect the chain of narrators
and the relation between each narrator, his ancestor, and 
his predecessor in the chain. 
We also detect the full name of each narrator that is
usually composed of several proper names with connectors
in between. 

We built our case-based controller to target
the detection of proper names. 
This includes the task of finding compound names 
composed of several words such as \RL{`bd alr.hmn} often
appearing as ``run-on'' words.
The controller also targets words that mean narrate when
they appear in the neighborhood of multiple proper names. 

\subsection{Controller}
% FSM for the controller
The FSA in Figure~\ref{f:hadith}


\section{Results}
\label{sec:results}

\subsection{Efficiency Comparison Against Buckwalter and SAMA}

\subsection{Case Study Accuracy and Efficiency Results}

% accuracy measure:
% on names: a word is a name or not
% chains: narrator is missing from a chain
% segmentation: two hadiths are merged

\section{Future Work}

%For reasons of uniformity, Adobe's {\bf Times Roman} font should be
%used. In \LaTeX2e{} this is accomplished by putting

%\begin{quote}
%\begin{verbatim}
%\usepackage{times}
%\usepackage{latexsym}
%\end{verbatim}
%\end{quote}
%in the preamble.

%Additionally, it is of utmost importance to specify the {\bf
%  US-Letter format} (8.5in $\times$ 11in) when formatting the paper.
%When working with {\tt dvips}, for instance, one should specify {\tt
%  -t letter}.

%{\bf Citations}: Citations within the text appear
%in parentheses as~\cite{Gusfield:97} or, if the author's name appears in
%the text itself, as Gusfield~\shortcite{Gusfield:97}. 
%Append lowercase letters to the year in cases of ambiguities.  
%Treat double authors as in~\cite{Aho:72}, but write as 
%in~\cite{Chandra:81} when more than two authors are involved. 
%Collapse multiple citations as in~\cite{Gusfield:97,Aho:72}.


\section*{Acknowledgments}

\bibliographystyle{naaclhlt2010}
\bibliography{fzAr}

\end{document}
