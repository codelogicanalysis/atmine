%
% File naaclhlt2010.tex
%
% Contact: nasmith@cs.cmu.edu

\documentclass[11pt,letterpaper]{article}
\usepackage{arabtex}
\usepackage{naaclhlt2010}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{times}
\usepackage{caption}
\usepackage{epsfig}
\usepackage{subfigure}
\usepackage{color}
\usepackage{rotate}
\usepackage{rotating}
\usepackage{multirow}
\usepackage{amsthm}

\usepackage{relsize}
\usepackage{fancyvrb}
%\usepackage{times}
\usepackage{latexsym}

\usepackage{utf8}
\setarab
\fullvocalize
%\transtrue
\arabtrue

\setlength\titlebox{6.5cm}    % Expanding the titlebox

%\title{Instructions for NAACL HLT 2010 Proceedings\Thanks{This...}}
\title{Case based Arabic Morphological Analysis with 
    Compositional Non-deterministic Automata }

%\author{ Jad Makhlouta \\
%  \And
%Hamza Harkous \\
%  American University of Beirut \\
%  {\tt \{jem04, hhh20, fz11\}@aub.edu.lb }
%  \And 
%  Fadi Zaraket 
%}

\date{}

\begin{document}
\maketitle

\begin{abstract}
Natural language processing uses morphological 
analysis to abstract and annotate text.
Often times, and in particular in the context
of the Arabic language, annotations resulting from 
an ongoing branch of morphological analysis may not be
appropriate for the case study at hand. 
In this paper we present Sarf, a case based morphological 
analyser for Arabic text. 
Sarf allows a case-based controller to control and refine
the state of the analysis on the fly. 
It uses compositional non-deterministic finite state machines 
to analyse a stream of text. 
Each alive machine corresponds to a valid analysis. 
Sarf uses concatenative analysis based on recursive affixes 
to better preserve part of speech information.
We automated the analysis of three books of Islamic
narrations (hadith) using Sarf where we
abstracted each book into a vector of complex structures.
Our results show high accuracy and efficiency compared to
state of the art analyzers. 
\end{abstract}

\section{Introduction}

Automated analysis of Arabic data sets, including texts, 
publications, records and digital media is essential
with the huge digital Arabic content available nowadays. 
Morphological analysis is key in current automated 
analysis techniques for Arabic text. 
Current morphological analyzers~\cite{Sughaiyer:04}
use concatenative analysis
to analyze an Arabic word and
consider its internal structure composed of several
{\em morphemes}. A morpheme can be a {\em stem}, or an {\em affix}.
An affix can be a {\em prefix, suffix, } or an {\em infix}.
The analysis of one word may lead to several possible
morphological solutions.
\vocalize
For instance the word \RL{'a.hmadH} 
may have two valid morphological analyses where in the first
\RL{'a} is a prefix and the word means ``I praise him'',
and in the second \RL{'a} is part of the stem 
\RL{'a.hmad} (a proper noun)
and the word means ``his Ahmad''.

\novocalize
The solutions suffer from accuracy due to inherent difficulties
of morphological analysis of the Arabic language. 
For example, it is common practice to write Arabic text
without short vowels. 
Arabic letters can also have up to four different shapes 
corresponding to their position in a word, i.e, begining of 
a word, middle of a word, end of word, and separated. 
This allows two consecutive words such as 
\RL{almdrsT}\RL{al_A}
to be visually recognizable
as two separate words \RL{al_A} and \RL{almdrsT} without 
the need of a delimiter such as a space in between. 
This specifically happens when the first word ends with
a non-connecting letter and is referred to as the ``run-o'' words
problem~\cite{Buckwalter:04}.
Such forms occur in text and greatly increase the
difficulty of tokenization.

Current morphological analyzers such as 
Buckwalter~\shortcite{Buckwalter:02},
Xerox~\cite{Beesley:01}, SAMA~\cite{Kulick:10},
and ElixirFM~\cite{Otakar:07} exist.
They take as input white space delimited tokens~\cite{Kulick:10},
consider them as words,
and enumerate all possible solutions. 
This exhaustive enumeration may hurt performance and may
not be necessary or appropriate
in some case studies as noted in~\cite{Maamouri:10}. 
Moreover, a white space delimited token may have 
more than one word.
Other morphological analyzers such as Amira~\cite{Diab:07,Benajiba:07},
MAGEAD~\cite{Habash:05}, and MADA+TOKAN~\cite{Habash:09} 
also use machine learning and support vector machines (SVM) 
to enhance the accuracy of the morphological analysis at the expense 
of perfomance.

We hypothesise that many NLP case studies need the 
morphological analyser to answer simple queries that do not need 
high complexity and accuracy at the low morphological analysis level 
and that can often compensate for tolerable inaccuracy at higher level. 
For example, if the query is interested in proper names and the 
prefix in question in the analysis can only connect to a verb, 
we can provide an answer without completing the analysis. 
%TODO A lso if a word such as \RL{wasiim} was name was ambiguous and we were looking for a sequence of names, then 
We find evidence to our hypothesis in~\cite{Maamouri:10} where the 
addition of a new corpus to the Arabic Tree Bank~\cite{Maamouri:04}
with features demanding resolution at an abstraction level
higher than the text itself
led to a refined analyzer~\cite{Kulick:10}.  
We also find evidence in~\cite{Habash:06} that different types of 
morphological analyses behave differently on the same case study. 
We strongly beleive and we find evidence in our results that a 
case-based controller intervening at every decision is necessary to 
guide, use, prune, and refine the morphological analysis.

\subsection{Sarf}
\label{sec:intro:sarf}

In this paper, we present Sarf, a {\em novel case-based efficient
morphological analyzer} that uses parallel compositional 
non-deterministic automata driven by a case based controller.
Each alive machine in Sarf represents a valid morphological analysis. 
Sarf keeps alive all possible analyses of the text and gives 
opportunity to the controller to intervene at every single input 
character. 
The decisions of the case-based controller can thus prune false 
positives early in the run. 
Each alive machine in Sarf takes as input one character at a time 
from a text stream. 
Sarf does not assume that the word at hand is a token and
performs tokenization on the fly based on morphological correctness.
To out knowledge, this is the first morphological analyzer that 
handles the ``run-on'' words problem. 

Sarf uses a {\em recursive} concatenative analysis with a novel 
refinement. 
Sarf introduces recursive affixes in order to
retain better part of speech information and enhance the 
efficiency of affix matching. 

We validate our hypothesis using a case study from the Islamic 
literature. 
A {\em hadith} is a narration related to the prophet Mohamad
through a {\em sanad} or a sequence of narrators. 
The authentication of a hadith higly depends on the credibility
of each of the narrators as reported in separate biography 
books. 
In this paper we consider the problem of automatically segmenting
a hadith book into narrations, then segmenting each narration into
its content or {\em matn} and its sanad.
We also would like to partition the sanad accurately into the 
separate narrators so that we can later look each one of them 
up in the biography books. 

The hadith case study is interesting for Sarf since the controller
considers most of the analyses where we have a concentration
of proper names in the text, and ignores most of the analyses as long 
as they are valid where we do not have proper names. 
The controller is also interested in a small subset of words 
that relate persons to each other such as \RL{bin} or ``the sun of''
or words that mean narrate such as \RL{qaal} or ``said''. 
With Sarf, we successfully automated the analysis of 
three books of Islamic narrations~\cite{narrations1,narrations2, narrations3}
and extracted from each one of them a vector of a three level deep
complex structure. 

%\subsection{Contributions}

We make the following key contributions. 
\begin{enumerate}
\item {\bf Case-based analysis:}  We deisgned and implemented
a case-based morphological analyzer where a case-based controller
machine controls and guides the analysis. 
\item {\bf Exhaustive analysis:} Since we have a case-based 
controller that can decide on the fly whether an analysis is 
accepted or not, we can afford to keep all valid analyses modulo
those pruned by the case controller. 
We do that using non-deterministic FSAs. 
\item {\bf Recursive affixes:}
We refine the concatenative analysis of 
Buckwalter~\shortcite{Buckwalter:02}  and use recursive affixes. 
This allowed Sarf to retain better compositional part of speech
tags.
\item {\bf Hadith case study:}
We evaluated Sarf using the hadith case study. We were able to
efficiently extract the sequence of narrators into a complex
data structure with three levels of hierarchy with high accuracy. 
\end{enumerate}



% does not have to be a subsection, 
%just to highlight it as an item we should not miss


% paper structure

\section{Background}

\section{Related Work }

Many morphological analyzers exist~\cite{Sughaiyer:04}. 
Some use specialized part of speech tag sets~\cite{Khoja:01,Darwish:02}.

Buckwalter: used lexicon, added proper nouns, word based, recursive affixes

MAGEAD

Beeseley: many compiled FSAs compared to compositions of three FSAs 

SAMA: word based, treebank specific, 

MADA+TOKAN: no controller, we do not need a tokenizer

AMIRA: machine learning... 

ElixirFM: 



\section{Sarf}

\subsection{Recursive Affixes}
% smaller FSM
% retain POS info

\subsection{Motivating Example}
% the FSMs for the three words
To help illustrate the strength of the method we imploy, we clarify it by walking through an example explaining the stages that lead to morphological analysis in SARF. Figure \ref{f:examples} shows a partial snapshot of the FSM's needed to analyze the following words: \RL{wsyal`bhaa}, \RL{syalbisohomaa} and \RL{al-laa`bown}.


\begin{figure*}[tb]
\center{
\resizebox{1.8\columnwidth}{!}
{ \input{psfigs/FSM.pstex_t}}
\caption{Example FSM.}
\label{f:examples}
}
\end{figure*}

\subsection{Affix Linear FSM}

\subsection{Stem Linear FSM}

\subsection{Non-deterministic Composition of FSMs}
% algorithm
% diagram of abstract machines
\begin{figure*}[tb]
\center{
\resizebox{1.8\columnwidth}{!}
{ \input{psfigs/abstract_machine.pstex_t}}
\caption{Abstract FSM.}
\label{f:abstract}
}
\end{figure*}

\section{Islamic Literature Case Study}

\subsection{Hadith Segmentation}

\subsection{Chain of Narrators} 

\subsection{Controller}
% FSM for the controller


\section{Results}
\label{sec:results}

\subsection{Efficiency Comparison Against Buckwalter and SAMA}

\subsection{Case Study Accuracy and Efficiency Results}

% accuracy measure:
% on names: a word is a name or not
% chains: narrator is missing from a chain
% segmentation: two hadiths are merged

\section{Future Work}

%For reasons of uniformity, Adobe's {\bf Times Roman} font should be
%used. In \LaTeX2e{} this is accomplished by putting

%\begin{quote}
%\begin{verbatim}
%\usepackage{times}
%\usepackage{latexsym}
%\end{verbatim}
%\end{quote}
%in the preamble.

%Additionally, it is of utmost importance to specify the {\bf
%  US-Letter format} (8.5in $\times$ 11in) when formatting the paper.
%When working with {\tt dvips}, for instance, one should specify {\tt
%  -t letter}.

%{\bf Citations}: Citations within the text appear
%in parentheses as~\cite{Gusfield:97} or, if the author's name appears in
%the text itself, as Gusfield~\shortcite{Gusfield:97}. 
%Append lowercase letters to the year in cases of ambiguities.  
%Treat double authors as in~\cite{Aho:72}, but write as 
%in~\cite{Chandra:81} when more than two authors are involved. 
%Collapse multiple citations as in~\cite{Gusfield:97,Aho:72}.


\section*{Acknowledgments}

\bibliographystyle{naaclhlt2010}
\bibliography{fzAr}

\end{document}
=======
%
% File naaclhlt2010.tex
%
% Contact: nasmith@cs.cmu.edu

\documentclass[11pt,letterpaper]{article}
\usepackage{arabtex}
\usepackage{naaclhlt2010}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{times}
\usepackage{caption}
\usepackage{epsfig}
\usepackage{subfigure}
\usepackage{color}
\usepackage{rotate}
\usepackage{rotating}
\usepackage{multirow}
\usepackage{amsthm}

\usepackage{relsize}
\usepackage{fancyvrb}
%\usepackage{times}
\usepackage{latexsym}
\usepackage[colorlinks=false]{hyperref}

\usepackage{utf8}
\setarab
\fullvocalize
%\transtrue
\arabtrue

\setlength\titlebox{6.5cm}    % Expanding the titlebox

%\title{Instructions for NAACL HLT 2010 Proceedings\Thanks{This...}}
\title{Case based Arabic Morphological Analysis with 
    Compositional Non-deterministic Automata }

%\author{ Jad Makhlouta \\
%  \And
%Hamza Harkous \\
%  American University of Beirut \\
%  {\tt \{jem04, hhh20, fz11\}@aub.edu.lb }
%  \And 
%  Fadi Zaraket 
%}

\date{}

\begin{document}
\maketitle

\begin{abstract}
Natural language processing uses morphological 
analysis to abstract and annotate text.
Often times, and in particular in the context
of the Arabic language, annotations resulting from 
an ongoing branch of morphological analysis may not be
appropriate for the case study at hand. 
In this paper we present Sarf, a case based morphological 
analyser for Arabic text. 
Sarf allows a case-based controller to control and refine
the state of the analysis on the fly. 
It uses compositional non-deterministic finite state machines 
to analyse a stream of text. 
Each alive machine corresponds to a valid analysis. 
Sarf uses concatenative analysis based on recursive affixes 
to better preserve part of speech information.
We automated the analysis of three books of Islamic
narrations (hadith) using Sarf where we
abstracted each book into a vector of complex structures.
Our results show high accuracy and efficiency compared to
state of the art analyzers. 
\end{abstract}

\section{Introduction}

Automated analysis of Arabic data sets, including texts, 
publications, records and digital media is essential
with the huge digital Arabic content available nowadays. 
Morphological analysis is key in current automated 
analysis techniques for Arabic text. 
Current morphological analyzers~\cite{Sughaiyer:04}
use concatenative analysis
to analyze an Arabic word and
consider its internal structure composed of several
{\em morphemes}. A morpheme can be a {\em stem}, or an {\em affix}.
An affix can be a {\em prefix, suffix, } or an {\em infix}.
The analysis of one word may lead to several possible
morphological solutions.
\vocalize
For instance the word \RL{'a.hmadH} 
may have two valid morphological analyses where in the first
\RL{'a} is a prefix and the word means ``I praise him'',
and in the second \RL{'a} is part of the stem 
\RL{'a.hmad} (a proper noun)
and the word means ``his Ahmad''.

\novocalize
The solutions suffer from accuracy due to inherent difficulties
of morphological analysis of the Arabic language. 
For example, it is common practice to write Arabic text
without short vowels. 
Arabic letters can also have up to four different shapes 
corresponding to their position in a word, i.e, begining of 
a word, middle of a word, end of word, and separated. 
This allows two consecutive words such as 
\RL{almdrsT}\RL{al_A}
to be visually recognizable
as two separate words \RL{al_A} and \RL{almdrsT} without 
the need of a delimiter such as a space in between. 
This specifically happens when the first word ends with
a non-connecting letter and is referred to as the ``run-o'' words
problem~\cite{Buckwalter:04}.
Such forms occur in text and greatly increase the
difficulty of tokenization.

Current morphological analyzers such as 
Buckwalter~\shortcite{Buckwalter:02},
Xerox~\cite{Beesley:01}, SAMA~\cite{Kulick:10},
and ElixirFM~\cite{Otakar:07} exist.
They take as input white space delimited tokens~\cite{Kulick:10},
consider them as words,
and enumerate all possible solutions. 
This exhaustive enumeration may hurt performance and may
not be necessary or appropriate
in some case studies as noted in~\cite{Maamouri:10}. 
Moreover, a white space delimited token may have 
more than one word.
Other morphological analyzers such as Amira~\cite{Diab:07,Benajiba:07},
MAGEAD~\cite{Habash:05}, and MADA+TOKAN~\cite{Habash:09} 
also use machine learning and support vector machines (SVM) 
to enhance the accuracy of the morphological analysis at the expense 
of perfomance.

We hypothesise that many NLP case studies need the 
morphological analyser to answer simple queries that do not need 
high complexity and accuracy at the low morphological analysis level 
and that can often compensate for tolerable inaccuracy at higher level. 
For example, if the query is interested in proper names and the 
prefix in question in the analysis can only connect to a verb, 
we can provide an answer without completing the analysis. 
%TODO A lso if a word such as \RL{wasiim} was name was ambiguous and we were looking for a sequence of names, then 
We find evidence to our hypothesis in~\cite{Maamouri:10} where the 
addition of a new corpus to the Arabic Tree Bank~\cite{Maamouri:04}
with features demanding resolution at an abstraction level
higher than the text itself
led to a refined analyzer~\cite{Kulick:10}.  
We also find evidence in~\cite{Habash:06} that different types of 
morphological analyses behave differently on the same case study. 
We strongly beleive and we find evidence in our results that a 
case-based controller intervening at every decision is necessary to 
guide, use, prune, and refine the morphological analysis.

\subsection{Sarf}
\label{sec:intro:sarf}

In this paper, we present Sarf, a {\em novel case-based efficient
morphological analyzer} that uses parallel compositional 
non-deterministic automata driven by a case based controller.
Each alive machine in Sarf represents a valid morphological analysis. 
Sarf keeps alive all possible analyses of the text and gives 
opportunity to the controller to intervene at every single input 
character. 
The decisions of the case-based controller can thus prune false 
positives early in the run. 
Each alive machine in Sarf takes as input one character at a time 
from a text stream. 
Sarf does not assume that the word at hand is a token and
performs tokenization on the fly based on morphological correctness.
To out knowledge, this is the first morphological analyzer that 
handles the ``run-on'' words problem. 

Sarf uses a {\em recursive} concatenative analysis with a novel 
refinement. 
Sarf introduces recursive affixes in order to
retain better part of speech information and enhance the 
efficiency of affix matching. 

We validate our hypothesis using a case study from the Islamic 
literature. 
A {\em hadith} is a narration related to the prophet Mohamad
through a {\em sanad} or a sequence of narrators. 
The authentication of a hadith higly depends on the credibility
of each of the narrators as reported in separate biography 
books. 
In this paper we consider the problem of automatically segmenting
a hadith book into narrations, then segmenting each narration into
its content or {\em matn} and its sanad.
We also would like to partition the sanad accurately into the 
separate narrators so that we can later look each one of them 
up in the biography books. 

The hadith case study is interesting for Sarf since the controller
considers most of the analyses where we have a concentration
of proper names in the text, and ignores most of the analyses as long 
as they are valid where we do not have proper names. 
The controller is also interested in a small subset of words 
that relate persons to each other such as \RL{bin} or ``the sun of''
or words that mean narrate such as \RL{qaal} or ``said''. 
With Sarf, we successfully automated the analysis of 
three books of Islamic narrations~\cite{IbnHanbal,AlTousi,AlKulayni}
and extracted from each one of them a vector of a three level deep
complex structure. 

%\subsection{Contributions}

We make the following key contributions. 
\begin{enumerate}
\item {\bf Case-based analysis:}  We deisgned and implemented
a case-based morphological analyzer where a case-based controller
machine controls and guides the analysis. 
\item {\bf Exhaustive analysis:} Since we have a case-based 
controller that can decide on the fly whether an analysis is 
accepted or not, we can afford to keep all valid analyses modulo
those pruned by the case controller. 
We do that using non-deterministic FSAs. 
\item {\bf Recursive affixes:}
We refine the concatenative analysis of 
Buckwalter~\shortcite{Buckwalter:02}  and use recursive affixes. 
This allowed Sarf to retain better compositional part of speech
tags.
\item {\bf Hadith case study:}
We evaluated Sarf using the hadith case study. We were able to
efficiently extract the sequence of narrators into a complex
data structure with three levels of hierarchy with high accuracy. 
\end{enumerate}



% does not have to be a subsection, 
%just to highlight it as an item we should not miss


% paper structure

\section{Background}

\section{Related Work }

The survey work in~\cite{Sughaiyer:04} discusses and compares
several morphological analyzers. 
Analyzers such as~\cite{Khoja:01,Darwish:02} 
target specific specific applications in the morphological 
analyzer itself or use a specific set of part of speech tags
as their reference.
Sarf differs in that it is a general and rich morphological 
analyzer that reports all possible solutions. 
It is case-based in the sense that a controller that drives
the morphological analyzers prunes these decisions. 
Up to our knowledge, Sarf is the only morphological analyzer
that addresses the ``run-on'' words problem. 

Sarf builds upon the lexicon of Buckwalter\shortcite{Buckwalter:02}.
It differs than Buckwalter where it defines a shorter list of affixes
and a longer list of affix compatibility rules to allow recursive 
affixes so that we can have prefix-prefix an suffix-suffix 
concatenations.
This allows Sarf to better maintain and propagate 
the part of speech information
tags associated with each prefix while these need to be highly 
redundant with Buckwalter and that may lead to consistency issues. 
Sarf keeps the possible analyses alive as a sequence corresponding
to the text. Buckwalter produces a set of solutions for each token 
and the several analysis threads of the whole text need to be 
generated as a product of the token solutions. 

Sarf is similar to Beesley~\shortcite{Beesley:01} in that it uses
finiste-state automata (FSA). 
Beesley reports that the number of the automata generated by a compiler
from Xerox rules is not controlled and also reports a difficulty to 
compose the FSAs into a single FSA framework. 
Sarf solves the problem with a non-deterministic composition of three
FSAs that are the prefix, stem, and suffix FSAs. 
With Sarf it is easy to control the FSAs with a user custom case 
controller, while with Beesley the effort requires recompiling the
Xerox rules.

Sarf is similar to The MADA+TOKAN toolkit in that it thinks of
the several valid morphological analyses as a richness that 
should be exploited at a higher abstract level rather than
an inaccuracy that should be corrected. 
Sarf differs in that it provides an interface for the 
case study to interfere in judging the analyses much earlier and
at a finer granularity level. 
Also in Sarf there is no need for a separate tokenizer such as
TOKAN as each alive automata carries with it the positions in 
text where a composition decision was made. 
The case-baded controller can build the trace when needed. 

%MAGEAD 
    %Maamouri, Mohamed and \bgroup et al.\egroup },

We strongly feel that the refinemet of SAMA~\cite{Maamouri:10} 
is the closest to our approach. SAMA was refined to interact with
the ATB~\cite{Maamouri:04} project after the addition of a large 
new corpus. We find evidence in this decision that our hypothesis
about the utility of case-based analyzers. The refinements
that resulted in algorithmic changes in SAMA were done manually
and worked in integration with the ATB format only. 
In Sarf we propse a case-based controller approach that can modify 
the behaviour of the analyzer on the fly and that should interact
with the case study. In Sarf the analyzer remains general, and the 
case-based controller specializes the analyses.

The AMIRA~\cite{Diab:07} analyzer uses 
a language independent SVM based analysis. 
While the SVM analysis learns features from the text passed to the case
study, it does not make use of the type oh the query the 
case study targets in the text. 

Like ElixirFM~\cite{Otakar:07} Sarf builds on the lexicon
of the Buckwalter analyzer. 
We also use deterministic parsing with tries or our analysis 
to run the prefix, suffix and stem FSAs. 
We think that their inferential-realizational approach 
that is highly compatible with the Arabic linguistic 
description~\cite{Badawi:04}
can make benefit of many features unique to the Arabic language.
Sarf leaves implementing that to the case-based controller
since in many cases the abstraction needed may not need the 
text to be grammar correct.
We can compare the case-based controller in Sarf to a high level
component in the ElixirFM domain sepcific language. 

\section{Sarf}

Sarf extends the lexicon of Buckwalter~\shortcite{Buckwalter:02} with 
proper names and location names extracted from different online 
sources~\footnote{\href{http://alasmaa.net/}{http://alasmaa.net/ }, 
\href{http://ar.wikipedia.org/}{http://ar.wikipedia.org/}}
as well as biblical sources~\cite{}. 


\subsection{Recursive Affixes}
% smaller FSM
% retain POS info

\subsection{Motivating Example}
% the FSMs for the three words


\begin{figure*}[tb]
\center{
\resizebox{1.8\columnwidth}{!}
{ \input{psfigs/FSM.pstex_t}}
\caption{Example FSM.}
\label{f:examples}
}
\end{figure*}

\subsection{Affix Linear FSM}

\subsection{Stem Linear FSM}

\subsection{Non-deterministic Composition of FSMs}
% algorithm
% diagram of abstract machines

\section{Islamic Literature Case Study}

\subsection{Hadith Segmentation}

\subsection{Chain of Narrators} 

\subsection{Controller}
% FSM for the controller


\section{Results}
\label{sec:results}

\subsection{Efficiency Comparison Against Buckwalter and SAMA}

\subsection{Case Study Accuracy and Efficiency Results}

% accuracy measure:
% on names: a word is a name or not
% chains: narrator is missing from a chain
% segmentation: two hadiths are merged

\section{Future Work}

%For reasons of uniformity, Adobe's {\bf Times Roman} font should be
%used. In \LaTeX2e{} this is accomplished by putting

%\begin{quote}
%\begin{verbatim}
%\usepackage{times}
%\usepackage{latexsym}
%\end{verbatim}
%\end{quote}
%in the preamble.

%Additionally, it is of utmost importance to specify the {\bf
%  US-Letter format} (8.5in $\times$ 11in) when formatting the paper.
%When working with {\tt dvips}, for instance, one should specify {\tt
%  -t letter}.

%{\bf Citations}: Citations within the text appear
%in parentheses as~\cite{Gusfield:97} or, if the author's name appears in
%the text itself, as Gusfield~\shortcite{Gusfield:97}. 
%Append lowercase letters to the year in cases of ambiguities.  
%Treat double authors as in~\cite{Aho:72}, but write as 
%in~\cite{Chandra:81} when more than two authors are involved. 
%Collapse multiple citations as in~\cite{Gusfield:97,Aho:72}.


\section*{Acknowledgments}

\bibliographystyle{naaclhlt2010}
\bibliography{fzAr}

\end{document}
