% File naaclhlt2010.tex
% Contact: nasmith@cs.cmu.edu
\documentclass[11pt]{article}
\usepackage{acl-hlt2011}
\usepackage{times}
\usepackage{latexsym}
\usepackage{amsmath}
\usepackage{multirow}
\usepackage{url}
\DeclareMathOperator*{\argmax}{arg\,max}
\setlength\titlebox{6.5cm}    % Expanding the titlebox

\usepackage{arabtex}
\usepackage{amssymb}
\usepackage{caption}
\usepackage{epsfig}
\usepackage{subfigure}
\usepackage{color}
\usepackage{rotate}
\usepackage{rotating}
\usepackage{amsthm}
\usepackage{booktabs}

\usepackage{relsize}
\usepackage{fancyvrb}
\usepackage[colorlinks=false]{hyperref}

\usepackage{utf8}
\setarab
\fullvocalize
\transtrue
\arabtrue


%\newcommand{\CharCodeIn}[1]{`\CodeIn{#1}'}
\newcommand{\CodeIn}[1]{{\small\texttt{#1}}}
\newcommand{\frl}[1]{\fbox{\RL{#1}}} 
\newcommand{\noArRL}[1]{\arabfalse\RL{#1}\arabtrue} 
\newcommand{\noTrRL}[1]{\transfalse\RL{#1}\transtrue}
\newcommand{\noTrnoVocRL}[1]{\transfalse\novocalize\noTrRL{#1}\vocalize\transtrue}  
\newcommand{\noVocRL}[1]{\transtrue\novocalize\RL{#1}\vocalize}  

%\title{Instructions for NAACL HLT 2010 Proceedings\Thanks{This...}}
%\title{Application-Specific Arabic Morphological Analyzer for Arabic Text Mining}% maybe add "with Enhanced Capabilities"
\title{Application-Specific Enhanced Morphological Analyzer \\for Arabic Text Mining}% maybe add "with Enhanced Capabilities"

%\author{ Jad Makhlouta \\\And
%Hamza Harkous \\
%  American University of Beirut \\
%  {\tt \{jem04, hhh20, fz11\}@aub.edu.lb } \\\And 
%  Fadi Zaraket 
%}

\date{}

\begin{document}
\maketitle
\begin{abstract}
Natural language processing (NLP) uses morphological 
analysis to annotate text.
Often times, 
%      and in particular in the context of the Arabic language, 
annotations resulting from 
a branch of morphological analysis may not be
appropriate for the NLP application. 
We present Sarf, 
%an application-specific morphological analyzer for Arabic. 
an Arabic application-specific morphological analyzer, which
%Sarf
allows a controller to refine
the analysis on the fly. 
It uses non-deterministic finite state Automata % (NDFSA)
to analyze a stream of text. 
%Each machine corresponds to a valid analysis. 
Sarf uses concatenative analysis 
%based on
with  
recursive affixes 
to better preserve part of speech (POS) information.
It solves the issue of ``run-on'' words 
and utilizes diacritics for disambiguation.
%We automated the analysis of three books of Islamic
%narrations (hadith) using Sarf, where we
%abstracted each book into a vector of complex structures.
Our results show better efficiency
compared to current analyzers.
\end{quote}
\end{abstract}

\section{Introduction}
 
Morphological analysis is key in current automated 
analysis techniques for Arabic text. 
The accuracy of the solutions suffers due to inherent difficulties
of morphological analysis of Arabic. 
For example, it is common practice to write Arabic text
without short vowels (diacritics) 
which greatly increases ambiguity.
Moreover, tokenization is not always 
trivial.
For example,
\noTrnoVocRL{il_A\nospace almdrsT}
can be visually recognizable
as two separate words \noVocRL{il_A} (to) and \noVocRL{almdrsT} (the school) 
without the need of a space in between. 
The reason is that
\noTrnoVocRL{_A} is a non-connecting letter. 
Such 
``run-on'' words~\cite{Buckwalter:04},
occur often.


%{\bf Sarf.~~~}
In this paper, we present Sarf~\footnote{Sarf (name modified for blind review) 
has been submitted with the paper and will be available 
as an open source tool.}, 
a {\em novel application-specific efficient 
%(maybe 'enhanced' instead of 'efficient' to engulf both efficiency and other refinements)
morphological analyzer} that uses 
non-deterministic finite state Automata (NDFSA)
driven by an application-specific controller.
Each machine in Sarf takes one letter at a time as input
and represents a valid morphological analysis.
%The application-specific controller prunes false positives
The controller prunes false positives
early in the run by making a decision at every input letter
to control the machines.
%The controller we present in Section~\ref{sec:controller}
%is an FSA. However, as we explain in Section~\ref{sec:ndfsa},
%it can be a logical entity of any type.
%since Automatas may be a %very complex
%non-necessary solution for some simple applications.
%(maybe re-word this sentence)
%depending on application needs.

%(check if position of this paragraph seems in correct place)
%Our focus when building Sarf, was not on improving the semantical rules and 
%expanding the morphological alternatives, instead we worked on adding support 
%for higher level control by the specific application utilizing the lower level 
%morphological analyzer. %In other words, the application-specific controller, has 
% full control over and directs the morphological analysis of Sarf. 
% (sentence should be reworded differently, but is needed to explain why we mention 
% higher and lower accuracy hypothesis, which seems vague otherwise)
%
%We have noted that many NLP case studies need the 
%morphological analyzer to answer queries that do not need 
%high accuracy at the morphological analysis level.
%The analysis at the higher levels 
%(i.e. answering the application-specific query)
%can often compensate for 
%tolerable inaccuracy at lower morphological levels. 
%For example, if a query concerns proper names and the 
%analyzer is considering a 
%prefix that connects only to a verb,
%%the analyzer can answer without considering the 
%%rest of the word.
%we do not need to further analyze the rest of the word 
%to provide a negative answer.
%
%We find evidence to our hypothesis in~\cite{Maamouri:10}.
%%The addition of a new corpus to the Arabic Tree Bank 
%%(ATB)~\cite{Maamouri:04}
%%%required compliance with the DARPA GALE program 
%%%including several NLP tasks such as English translation 
%%%annotations and word-level alignment of Arabic and English. 
%%%The new data 
%%challenged the existing processing and 
%%annotation guidelines. 
%%This led to refining 
%%SAMA~\cite{Kulick:10} with 
%%alternative guidelines. 
%%This refinement was achieved only after the NLP 
%%task interacted with the morphological analyzer,
%%a flexibility our analyzer is designed to provide for the application-specific controller on the run. %(check if this sentence makes sense)
%It reports that a refined version of SAMA~\cite{Kulick:10} was achieved when NLP task interacted with the morphological analyzer.
%%a flexibility our analyzer is designed to provide for the application-specific controller on the run.
%In addition, 
%the work of Habash~\shortcite{Habash:06} reports that different 
%types of morphological analyses behave differently on the same %case study. 
%data set.
%The analyzers may report different solutions or 
%may present the solutions in different orders. 
%Clearly, some of 
%the presented solutions and their order of presentation may not be 
%appropriate for the %case study.
%application needs, which is an issue that Sarf tackles. % (maybe reworded)
We hypothesize that in many NLP applications, the morphological analyzer may
benefit from the characteristics of the query at hand, 
to greatly enhance the analysis.
Consequently, %we believe that by 
%being 
%allowing
an application-specific %morphological 
%analyzer that allows %an application-specific 
%the
controller that intervenes at every decision to guide, use, order, and 
refine the morphological analysis is of high utility.

%Each alive machine in Sarf takes as input one letter at a time 
%from a text stream.
%Apart from being application-specific, 
Sarf %has
also  
introduces 
several enhancements. %to the field of Arabic morphological analysis. 
%the following enhancements:
%For example,
First,
Sarf %does not assume that the word at hand is a token and
performs tokenization on the fly based on morphological correctness.
Up to our knowledge, this is the first %morphological 
analyzer that 
handles %the ``run-on'' words problem. 
``run-on'' words. 
%
%Moreover, since Sarf performs tokenization on the fly, Sarf is not just capable of solving
%the problem of ``run-on'' words, but also of handling Multiword Expressions (MWE). 
On the fly tokenization also handles
Multiword Expressions (MWEs)~\cite{MWE} such as \noVocRL{`bid alkarym}.
%MWEs are defined in~\cite{MWE} as
%which are 
%``idiosyncratic interpretations
%that cross word boundaries (or spaces)''. 
%By this term, we refer to frequent cases when a group of words form together a single
%item with a semantical meaning. In this paper, we focus on the example of compound names such as 
%\noVocRL{`bid alkarym}. 
%In current analyzers, this phrase is analyzed word by word and in best cases is 
%considered to contain two names, instead of being understood to be a single but compound name.  

Second, 
Sarf uses concatenative analysis with a novel %(maybe remove novel bc authors did not feel it is much)
{\em recursive affixes} refinement,
%where an affix can be a sequence of other affixes which are concatenatively compatible.
where an affix can be a sequence of other compatible affixes.
%An atomic affix $a$ is a standalone affix
%that is not the concatenation of other affixes. 
%We define an affix $f: a | a f$ to be either
%an atomic affix $a$ or an atomic affix concatenated
%with an affix. 
%Sarf introduces recursive affixes in order to
%This refinement is introduced to better retain
Hence, it better retains
%part of speech information
POS information  
and enhances the 
efficiency of affix matching. 
Third, Sarf supports disambiguation using 
%diacritics when they are available.
available diacritics, instead of the traditional approach that ignores them.
%This feature, to the best of our knowledge is the first attempt to benefit from 
%To the best of our knowledge,
%Up to our knowledge, this is the first attempt to benefit from
%diacritics instead of ignoring them. 
%Nonetheless, Sarf regards them as a richness to be utilized that should not be disregarded.

%In addition to all its enhanced analysis methods, Sarf still
%Sarf also
%outperformed current morphological analyzers in terms of running time,
%%These results will be presented 
%as shown in Section~\ref{sec:results}.
Sarf is also more efficient than current morphological analyzers, 
as shown in Section~\ref{sec:results}.


%%We make the following 
%We summarize our key contributions: 
%\begin{enumerate}
%\item {\bf application-specific analysis:}  We designed and implemented
%a application-specific morphological analyzer where a controller
%guides the analysis. 
%%\item {\bf Exhaustive analysis:} Since we have an application-specific 
%%controller that can decide on the fly whether an analysis is 
%%accepted or not, we can afford to keep all valid analyses modulo
%%those pruned by the case controller. 
%%We do that using non-deterministic FSAs. 
%\item {\bf Recursive affixes:}
%We refine the concatenative analysis of 
%Buckwalter~\shortcite{Buckwalter:02} and define affixes
%recursively. 
%This allows Sarf to perform better and 
%maintain compositional part of speech (POS) tags.
%\item {\bf Diacritic-based Disambiguation:}
%Diacritics are used to disambiguate morphological
%alternatives using any existant diacritics.
%\end{enumerate}

%The rest of this paper is structured as follows. In Section~\ref{sec:related}
%we compare Sarf to related work. In Section~\ref{sec:sarf}
%we discuss Sarf and illustrate it with a running example.
%%We also explain how non-deterministic finite state Automata
%%work. 
%In Section~\ref{sec:islamic} we present the case
%study. We present our results in Section~\ref{sec:results}
%and conclude with future work in Section~\ref{sec:future}.

% does not have to be a subsection, 
%just to highlight it as an item we should not miss

%\section{Background}
% TODO: nondeterministic finite-state automata

\subsection{Related work }
\label{sec:related}

The survey in~\cite{Sughaiyer:04} compares
several morphological analyzers. 
Analyzers such as~\cite{Khoja:01,Darwish:02} 
target specific applications 
%in the analyzer itself or use a specific set of POS tags as their reference
or limit themselves to a specific set of POS tags. 
Sarf differs in that it is a general morphological 
analyzer that reports all possible solutions. 
It is application-specific in the sense that a controller 
prunes these solutions. 

Buckwalter~\shortcite{Buckwalter:02},
Beesley~\shortcite{Beesley:01},
SAMA~\cite{Kulick:10},
and ElixirFM~\cite{Otakar:07} 
consider white-space delimited tokens~\cite{Kulick:10}
as words.
%This suffers has several problems. 
%However, we note the following: %(I thought of this change not to include point 2 as a "problem" according to reviewer comments)
This fails when a white-space delimited token has
more than one word or is part of an MWE.
%Second, the exhaustive enumeration may hurt performance and may
%not be necessary or appropriate
%in some case studies as noted in~\cite{Maamouri:10}. 
These analyzers also exhaustively enumerate all 
possible morphological solutions 
which may not be appropriate in many applications
~\cite{Maamouri:10}. 
%consequently, adding unnecessary running time.

Others such as 
AMIRA~\cite{Diab:07,Benajiba:07},
MAGEAD~\cite{Habash:05}, and MADA+TOKAN~\cite{Habash:09} 
use machine learning and support vector machines (SVM) 
to disambiguate the morphological analysis at the expense 
of efficiency.
Xerox rules can be compiled into specialized 
finite state Automata (FSA)~\cite{Beesley:03}.
%FSA-based analyzers~\cite{Beesley:03}.
The efficiency of the resulting analyzer depends on the
way the rules are written. 
This requires deep knowledge and insight from the user
in compilation techniques, context free grammars, 
and morphological analysis.
%context free grammar rules that can be automatically compiled
%into efficient non-deterministic finite state Automata (NDFSA). 
Beesley reports that the number of Automata generated by a compiler
for Xerox rules can not be controlled and also reports a difficulty 
to compose the FSAs into a single framework. 
%Beesley requires recompilation of the Xerox rules. 
% (I am not sure if it is ok to have the above removed)
Sarf however constructs an NDFSA from 
%the controller and 
the prefix, stem, and suffix deterministic 
transducers to solve the problem.
Sarf also differs in that 
%it uses recursive affixes in the affix transducers, and in that 
the transducers consider
input from the controller to modify their behavior.
The user can express the controller,not necessarily an FSA, in a programming language such as C++.

Sarf builds upon the lexicon of Buckwalter. %\shortcite{Buckwalter:02}, %(already cited above)
%It differs from Buckwalter in that it defines a shorter list of affixes
It defines a shorter list of affixes
and a longer list of 
%affix 
compatibility rules to define 
affixes recursively and allow 
prefix-prefix and suffix-suffix 
concatenations.
%This allows Sarf to better maintain and propagate 
This better maintains and propagates 
the tags associated with affixes. 
%This information is highly 
%redundant with Buckwalter.% and that may lead to consistency issues. 
% (check if necessary to keep the 2 sentences below)
%Sarf keeps all the possible analyses alive where each analysis
%corresponds to a set of decisions and positions in the text. 
%Buckwalter produces a set of solutions for each token 
%and the several analysis threads of the text need to be 
%generated as a product of the token solutions. 
Similar to Sarf, Attia uses FSAs and handles more and qualitatively different MWEs
~\cite{Attia:06,Attia:10}.
%Attia has researched extensively MWEs handling methods~\cite{Attia:06} and 
%automated extending their dictionary coverage~\cite{Attia:10}. 
% (I am not sure how clear this statement is)

%Similar to %the 
%MADA+TOKAN, Sarf uses
%the several valid morphological analyses as 
%%a richness that should 
%richness at a higher abstract level, and does not view them as 
%inaccuracies to be corrected. 
Sarf differs from MADA+TOKAN in that it provides an interface for the 
application to interfere in judging the analyses much earlier and
at a finer granularity level. 
%In Sarf, there is no need for a separate tokenizer such as
Sarf does not need a separate tokenizer such as
TOKAN since each solution keeps a stack of positions
that partition text into morphemes.
%The application-specific controller can build the trace 
%when needed. 

%MAGEAD 
%Maamouri, Mohamed and \bgroup et al.\egroup },


SAMA~\cite{Maamouri:10} was refined after the addition of a new corpus to 
the ATB~\cite{Maamouri:04}, since the new data challenged the existing processing and 
annotation guidelines.
The modification involved interaction between SAMA and the NLP 
task and resulted in alternative guidelines. 
Sarf supports such an interaction on the fly.

%The AMIRA %~\cite{Diab:07}
%analyzer uses 
%a language independent SVM-based analysis. 
%%The SVM 
%This 
%analysis learns features from the input text 
%but does not make use of any information 
%in the target query.

Like ElixirFM~\cite{Otakar:07}, Sarf builds on the lexicon
of Buckwalter. %analyzer. 
Sarf also uses deterministic parsing with tries 
to implement the affix and stem transducers. 
The inferential-realizational approach 
of ElixirFM
is highly compatible with the Arabic linguistic 
description~\cite{Badawi:04}.
%can benefit from many features unique to the Arabic language.
Sarf leaves implementing that to the %application-specific 
controller
since in many applications the abstraction needs only a partial 
linguistic model. 
%We can compare the application-specific controller in Sarf to a high level
%component in the ElixirFM domain specific language. 


\section{Sarf}
\label{sec:sarf}

%Sarf extends the lexicon of Buckwalter~\shortcite{Buckwalter:02} with
%proper names and location names extracted from different online 
%sources~\footnote{\href{http://alasmaa.net/}{http://alasmaa.net/ }, 
%\href{http://ar.wikipedia.org/}{http://ar.wikipedia.org/}}
%as well as biblical sources~\footnote{Genesis 4:17-23; 5:1-32; 9:28-10:32; 11:10-32; 25:1-4, 12-18; 36:1-37:2; Exodus 6:14-25; Ruth 4:18-22; 1 Samuel 14:49-51; 1 Chronicles 1:1-9:44; 14:3-7; 24:1; 25:1-27:22; Nehemiah 12:8-26; Matthew 1:1-16; Luke 3:23-38}.

Sarf encodes the prefix, suffix and stem lexicons into
three deterministic transducers and 
uses a non-deterministic construction
of the three to compute all valid morphological analyses.
We first present a running example 
%of Sarf. The running example 
that 
explains how Sarf works,
implements recursive affixes, and
handles ``run-on'' words.
%Then we discuss how Sarf builds and composes the different FSAs.

%\subsection{Sarf example}
%\label{sec:example}

\transfalse
\begin{figure}[tb]
\center{
\resizebox{\columnwidth}{!}
{ \input{figs/FSM.pdftex_t}}
\caption{Example affix and stem transducers.}
\label{f:example}
}
\end{figure}
% the FSMs for the three words
%\transtrue

{\bf Sarf example.~~~}
The diagram in Figure~\ref{f:example}
illustrates the operation of $\Phi$, the Sarf FSA,
when parsing the
string \noTrnoVocRL{wsyl`b-h-aa\nospace al--lA`bwn} \noArRL{wsyl`b-h-aa al--lA`bwn}.
%\RL{al-lA`bwn}\RL{wsyl`b-h-aa}.
%\footnote{ 
%%\noVocRL{n}%
%%\noVocRL{w}
%%\noVocRL{b}
%%\noVocRL{`}
%%\noVocRL{a} 
%%\noVocRL{l}
%%\noVocRL{l}
%%\noVocRL{a} %
%%\noVocRL{a}
%%\noVocRL{h}
%%\noVocRL{b}
%%\noVocRL{`}
%%\noVocRL{l}
%%\noVocRL{y}
%%\noVocRL{s}
%%\noVocRL{w}
%\noTrnoVocRL{n}%
%\noTrnoVocRL{w}
%\noTrnoVocRL{b}
%\noTrnoVocRL{`}
%\noTrnoVocRL{a} 
%\noTrnoVocRL{l}
%\noTrnoVocRL{l}
%\noTrnoVocRL{a} %
%\noTrnoVocRL{a}
%\noTrnoVocRL{h}
%\noTrnoVocRL{b}
%\noTrnoVocRL{`}
%\noTrnoVocRL{l}
%\noTrnoVocRL{y}
%\noTrnoVocRL{s}
%\noTrnoVocRL{w}
%in separate form% to ease following the example
%}

Boxes and circles denote accept and regular
states respectively.
The edges are transitions with labels corresponding to
the input letters.
The reject states are omitted for clarity and are denoted
by the absence of corresponding transitions. 
Subfigures (a), (b), and (c) in Figure~\ref{f:example}
represent ${\cal P}$ the prefix ,
${\cal S}$ the stem, and ${\cal X}$ the suffix
transducers respectively. 
The symbol $\epsilon$ represents an empty string and is 
the source of non-determinism.

We start with $\Phi$ at the root accept state 
in ${\cal P}$. 
%The $\epsilon$-edge connects ${\cal P}$
%to ${\cal S}$ and transitions from any accept state
%in ${\cal P}$ to the root state in ${\cal S}$.
%The $\epsilon$-edge that connects ${\cal S}$ to ${\cal X}$
%follows the same behavior. 
The $\epsilon$-edges connect ${\cal P}$
to ${\cal S}$  and ${\cal S}$ to ${\cal X}$.
They transition from any accept state
in the current transducer to the root state of the target transducer.

When there are two valid transitions such as \noTrnoVocRL{w} 
and $\epsilon$ in the start case, 
$\Phi$ spawns an exact copy of itself $\Psi$. 
$\Phi$ makes one transition, and $\Psi$ makes the other. 
Each of $\Phi$ and $\Psi$ represent a valid analysis so far. 
An FSA %($\Phi$ or $\Psi$) 
dies when it reaches a reject state.
In our example, if there were no stems that start 
with the letter \noTrnoVocRL{w}, $\Psi$ will die. 
In reality, $\Psi$ will die when the input 
is at \noTrnoVocRL{wsyl`}. 

Note that the affix transducers allow recursive 
affixes. 
For example, \noTrnoVocRL{w} 
%will result 
results 
in an accept state
that transitions to ${\cal S}$.
When \noTrnoVocRL{s} follows, we move to another accept state in 
${\cal P}$ corresponding to 
%the 
prefix \noTrnoVocRL{ws}. 
%The same applies to ${\cal X}$. 

Lets consider $\Phi$ after it consumed \noTrnoVocRL{wsy} 
and transitioned into the root node of ${\cal S}$.
Now $\Phi$ will transition with \noTrnoVocRL{l`b} to reach an accept 
state. 

Before moving with the letter \noTrnoVocRL{b} to the accept state,
$\Phi$ needs to make sure that %the 
stem \noTrnoVocRL{l`b} is compatible
with %the 
prefix \noTrnoVocRL{wsy}. 
Sarf keeps compatibility information as part
of the accept states. 
%Sarf considers the value of the category as part of the state.
Thus each accept state in Figure~\ref{f:example} represents
more than one concrete state. 
If the categories of \noTrnoVocRL{l`b} and \noTrnoVocRL{wsy} are compatible
then \noTrnoVocRL{b} will move $\Phi$ to an accept state. 
Otherwise, it will move it to a regular or a reject state. 
       
Since $\Phi$ is now in an accept state in ${\cal S}$, it 
spawns $\Xi$ which transitions to the root of ${\cal X}$. 
After it consumes \noTrnoVocRL{h--} $\Phi$ dies since there is no
\noTrnoVocRL{h--}-edge from the current state.
$\Xi$ represents a valid analysis and proceeds.
       
Note that $\Xi$ reports a full word at any accept state
by spawning a new FSA using the $\epsilon$ transition
to ${\cal P}$.
In Sarf, this only happens with white space, delimiters, 
and non-connecting letters. 
We left that out in Figure~\ref{f:example} for clarity. 
       
%The application-specific controller can interfere at any point in the 
%analysis to make a decision like ignoring a solution that 
%is not interesting. 
%It may also decide to correct one solution
%based on the decision of the others. 
%The controller uses the output of the transducers as input
%to make 
%%its decision. 
%refinement decisions.
%%It does not produce external output and therefore 
%%the three transducers with the 
%%controller compose an FSA.

%\subsection{Recursive affixes}
%\label{sec:recaffix}
{\bf Recursive affixes.~~~}
We call two morphemes compatible if their concatenation
forms a legal morpheme. 
Buckwalter~\shortcite{Buckwalter:02} keeps separate lists 
of affix and stem morphemes and assigns categories to
morphemes. 
%The relation between morphemes and categories is one 
%to many. 
A compatibility rule is a pair of categories 
$\langle c_1, c_2\rangle$  stating that $c_1$ morphemes
can be concatenated with $c_2$ morphemes.
Buckwalter keeps three lists $L_{ps}, L_{sx},$ and $L_{px}$ 
of compatibility rules relating
prefixes to stems, stems to suffixes, and prefixes to suffixes
respectively. 
Consider a string $s=\alpha\beta\gamma$ where $\alpha$ is 
a prefix, $\beta$ is a stem, and $\gamma$ is a suffix;
$\alpha\beta\gamma$ is a 
valid morphological analysis iff
$\langle c(\alpha),c(\beta)\rangle \in L_{ps}$ and
$\langle c(\beta),c(\gamma)\rangle \in L_{sx}$ and
$\langle c(\alpha),c(\gamma)\rangle \in L_{px}$, where
$c()$ returns the category of the morpheme.

Many affixes are composed of other affixes. For example,
the prefix \noTrnoVocRL{wsy} is composed of three other prefixes
namely \noTrnoVocRL{w}, \noTrnoVocRL{s}, and \noTrnoVocRL{y}.
The POS tag for \noTrnoVocRL{wsy} is a concatenation
%of the POS tags of each of the three morphemes. 
of those of the three morphemes. 
Keeping all valid morphemes in a list
is redundant and may lead to consistency issues when
users try to add their custom morphemes.
We introduce $L_{pp}$ and
$L_{xx}$ as prefix-prefix and suffix-suffix 
compatibility rules respectively.
%This allows us to keep a shorter list of affixes. 
We also introduce a {\em resulting category}
for the $L_{pp}$ and  $L_{xx}$ resulting morphemes.
%The resulting category in all practical cases
%is that of the second morpheme in the pair. 

%Sarf only keeps atomic affixes and their categories.

\subsection{Affix transducers}
\label{sec:affixFSA}

We analyzed the prefixes and suffixes of 
Buckwalter~\shortcite{Buckwalter:02}
and constructed the recursive affixes
into directed acyclic graphs (DAG) similar to 
those in Figures~\ref{f:example}(a) and~\ref{f:example}(c).
The transducers are deterministic and thus 
their traversal is linear.
This is computationally superior to the 
approach of Buckwalter where the analyzer considers
all possible substrings %of the word in question
and looks them up in the affix tables. 

%The affix transducers encode $L_{pp}$ and
%$L_{xx}$.
%An accept state in the transducer corresponds to the last letter 
%of an affix in the affix lists.
%The accept states produce as output the POS and other tags
%associated with the state.
%(check if it is not a loss of information to remove it)

\subsection{Stem transducer}
\label{sec:stemFSA}

%We built our stem lexicon using the stem lexicon of 
%Buckwalter. 
%We augmented the lexicon with a set of proper names and
%a set of location names which we 
%obtained from online and biblical sources. 

%The stems share lots of substrings. 
Since stems share lots of substrings. 
We encoded them in
an efficient double array trie (DAT) structure~\cite{Aoe:89}. 
The structure is deterministic and free of cycles where the 
accept states are the terminal nodes corresponding to the last 
letters in stems. 
%Note that DAT is a suffix trie implementation which may not 
%necessary work on letter-by-letter states, but also compacts
%common substrings.
This approach is superior to Buckwalter since it consists of
a linear walk in the trie while with Buckwalter we need
a number of hash lookups in the order of all possible partitions
of the string.

\subsection{Construction of Sarf from transducers}
\label{sec:ndfsa}

%The diagram in Figure~\ref{f:composition} shows an 
%abstraction of the non-deterministic construction of Sarf
%from the prefix, stem and suffix transducers. 
%The circle represents regular states, the square
%represents accept states and the triangle represents
%reject states. 
%Note that the concrete prefix, stem and suffix transducers
%are all deterministic and cycle free as discussed 
%in Sections~\ref{sec:affixFSA} and~\ref{sec:stemFSA}.
%The cycles are introduced in the abstract machine
%for pedagogical purposes.
%
%%Note that Sarf does not rely on implementing its machines as 
%%equivalent regular expressions due to  the following reasons ...
%% (not necessary)
%
%\begin{figure}[tb]
%\center{
%\resizebox{\columnwidth}{!}
%{ \input{figs/abstract_machine.pdftex_t}}
%\caption{Sarf NDFSA.}
%\label{f:composition}
%}
%\end{figure}

The algorithm \CodeIn{NDSarf} (detailed below)
takes as input a text string $L$ and a application-specific controller
$A$. 
It starts with one machine $\Phi_1$ similar to the one in 
Figure~\ref{f:example} and inserts it into a collection
$M$. 
The algorithm reads a letter $c$ at a time from $L$
and iterates over all machines in $M$. 
For each $\Phi$ in $M$,
if $\Phi$ is in an accept state and it is in the suffix
phase, then the algorithm checks whether it should report
a full word. 
This happens when $c$ is a white space, a delimiter, 
or when the preceding letter %leading to the current state
was a non-connecting letter. 

In all cases, if $\Phi$ is in an accept state, 
it spawns another machine $\Psi$ and adds it to $M$. 
Notice that spawning a new machine requires only keeping
the state of the machine since all machines share the
structures of the three transducers.
If $c$ leads to a reject state, then $\Phi$ dies 
and we remove it from $M$. 
Otherwise, $\Phi$ transitions using the $c$ edge.
After iterating over all machines in $M$, we invoke the 
controller $A$
and grant it full access and control over
all machines in $M$. 

%The arrows in Figure~\ref{f:composition} that transition
%from prefix to stem, stem to suffix, and suffix to prefix
%require compatibility constraints for 
%the transition.

\begin{table}[tb]
%\centering
%\resizebox{.9\columnwidth}{!}{
\begin{tabular} {p{6cm}}
\begin{Verbatim}[fontsize=\relsize{-2},
frame=topline,framesep=4mm,label=\fbox{NDSarf algorithm},
commandchars=\\\{\}, codes={\catcode`$=3\catcode`_=8}]
NDSarf(string $L$, Controller $A$) 
  MachineVec $M$; -- collection of machines
  Machine $\Phi_1$;
  $M$.insert($\Phi_1$);
  foreach $c$ in $L$ \{
    foreach $\Phi$ in $M$ \{
      if ( $\Phi$.state.isAccept() ) \{
        if ($\Phi$.isSuffix())
          if ($c$.isWhite())  
            $A$.report();
          if ($\Phi$.lastChar().isNonConnecting())
            $A$.report();
        $\Psi$ = $\Phi$.clone();
        $M$.insert($\Psi$); \}

      if ( $\Phi$.isWalkable($c$) ) \{
        $\Phi$.transition($c$);
      \} else \{
        $M$.remove($\Phi$);
        $\Phi$.die();
      \} \} 
    $A$.control($M$, $c$); \}
\end{Verbatim}
\end{tabular}
%}
\label{a:ndsarf}
\end{table}

%\subsection{Disambiguation using diacritics}
{\bf Disambiguation using diacritics.~~~}
%\label{sec:diacritics}
Many Arabic documents, especially religious texts, are fully vocalized.
Even in documents written without diacritics, we often %stumble at 
notice 
a couple of words which are partially vocalized
to reduce the difficulty of their disambiguation by the reader. Clearly, if native readers
need the aid of short vowels, automatic morphological analyzers which are context-free should not lose this precious piece of information.
%Sarf is the first in the field to support diacritic-based disambiguation. Consequently, 
Sarf does not confuse \RL{bon} (coffee beans) with \RL{bin} (child)
or \RL{`ilm} (science) with \RL{`lim} (knew), regardless of the specific letters which are vocalized.

%The lexicon of buckwalter contains the vocalized equivalent of each entry, however makes no use of their power. 
%On the other hand, in Sarf's transducers after each accept state an (optional) linear-time diacritic based equality function is run
%to check if the state should be reported to the controller. Accordingly, much unnecessary ambiguity is reduced.

%\subsection{Multiword Expressions}
%\label{sec:MWE}
{\bf Multiword Expressions.~~~}
%The names which have been augmented to the lexicon of Sarf contain compound names such as 
%Some of the names which have been augmented to the lexicon of Sarf are compound such as
%
Current analyzers, with the exception of Attia, fail to recognize MWE such as \noTrnoVocRL{`bid alkarym}, and 
report it as two consecutive names. 
Sarf includes such expressions in the stem transducer (with one letter being the space) and 
detects them as one unit since tokenization
is performed on the fly. The multi-word stems
can accept some compatible affixes such as \RL{w} (and) and \RL{f-} (but).
This approach works for proper names but not for ``Syntactically-Flexible Expressions''~\cite{MWE}.
%MWEs that can undergoe lexical inflections for their constituent words

\section{Results}
\label{sec:results}

\begin{table}[tb]
\centering
\caption{Results of Sarf, Buckwalter and ElixirFM.}
\resizebox{0.9\columnwidth}{!}{
%\begin{tabular}{lp{.01cm}cp{.01cm}cp{.01cm}c}
\begin{tabular}{lccc}
\hline
 & Al Kafi & Al Istibsar & Ibn Hanbal \\ \cline{2-4} 
Word Count & 98,943 & 103,835 & 20,354 \\
Sarf (sec) & 2.70 & 2.69 & 0.236 \\
Sarf/Controller (sec) & 1.32 & 1.31 & 0.0960 \\
Buckwalter (sec) & 3.32 & 5.41 & 0.547 \\
ElixirFM (sec) & 167$\times60$ & 138$\times60$ & 29.2$\times$60 \\
\hline
\end{tabular}
}
\normalsize
\label{t:efficeincyresults}
\end{table}

%In this section we compare Sarf to existing 
%morphological analyzers such as Buckwalter and ElixirFM in terms of running time.
We ran Sarf without a controller then with a controller that only 
focused on proper names and words that are related to the word ``narrated".
We compared the running times to those of Buckwalter and ElixirFM.
We used three books of Islamic narrations \RL{.hady_t} ~\cite{IbnHanbal,AlTousi,AlKulayni} as our data set.
We report our results in Table~\ref{t:efficeincyresults}.

With a controller, Sarf performed much better since the controller pruned several solutions irrelevant to the application. 
Sarf, with and without a controller, was more efficient than both Buckwalter and ElixirFM. 
Buckwalter performed much better than ElixirFM in 
terms of running time. 
The difference may be due to the sophisticated formal 
functional morphological analysis of ElixirFM. 
%and its reliance on additional annotations extracted from 
%both ATB~\cite{Maamouri:04} and the Prague Arabic Dependency Treebank~\cite{Prague04}.

\section{Conclusion and Future Work}
\label{sec:future}

We presented Sarf, a novel application-specific morphological analyzer,
which supports diacritic-based disambiguation and introduces recursive affixes.
%Sarf uses non-deterministic finite state Automata with 
%concatenative analysis and recursive affixes to analyze 
%Arabic text. 
Results show that Sarf is faster than
current morphological analyzers.

In the future, we will use Sarf to fully automate the analysis of Islamic Narrations 
from Prophet Muhammad commonly known as hadith.
We will also use Sarf to automate the classification of
Arabic emails. Another application where we are looking to use Sarf is
Arabic web content analysis to flag violent and inappropriate material for parental control.
Those applications will benefit from the application-specific nature of Sarf.

%In the future, 
%we will try Sarf with other interesting case studies.
%We plan to complete the hadith case study 
%and automate narrator discovery and authentication in the 
%biography books. 
%%We plan to make use of the name connector and narrator
%%connector stop phrases that our case study extracted to create a 
%%learning system that can learn more names. 
%%We also plan on developing an Arabic linguistic computational model 
%%similar to that of ElixirFM~\cite{Otakar:07} but that can be 
%%explored partially based on the case study. 

%\section{Acknoledgements}
%\label{sec:acc}
%We thank the Lebanese National Council for Scientific Research (LNCSR) for funding this research.


%For reasons of uniformity, Adobe's {\bf Times Roman} font should be
%used. In \LaTeX2e{} this is accomplished by putting

%\begin{quote}
%\begin{verbatim}
%\usepackage{times}
%\usepackage{latexsym}
%\end{verbatim}
%\end{quote}
%in the preamble.

%Additionally, it is of utmost importance to specify the {\bf
%  US-Letter format} (8.5in $\times$ 11in) when formatting the paper.
%When working with {\tt dvips}, for instance, one should specify {\tt
%  -t letter}.

%{\bf Citations}: Citations within the text appear
%in parentheses as~\cite{Gusfield:97} or, if the author's name appears in
%the text itself, as Gusfield~\shortcite{Gusfield:97}. 
%Append lowercase letters to the year in cases of ambiguities.  
%Treat double authors as in~\cite{Aho:72}, but write as 
%in~\cite{Chandra:81} when more than two authors are involved. 
%Collapse multiple citations as in~\cite{Gusfield:97,Aho:72}.


%\section*{Acknowledgments}
% this will go into the regular submission

%\bibliographystyle{naaclhlt2010}
\bibliographystyle{acl}
{\small \bibliography{fzAr}}

\end{document}
