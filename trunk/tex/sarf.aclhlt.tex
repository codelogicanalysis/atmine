% File naaclhlt2010.tex
% Contact: nasmith@cs.cmu.edu
\documentclass[11pt]{article}
\usepackage{acl-hlt2011}
\usepackage{times}
\usepackage{latexsym}
\usepackage{amsmath}
\usepackage{multirow}
\usepackage{url}
\DeclareMathOperator*{\argmax}{arg\,max}
\setlength\titlebox{6.5cm}    % Expanding the titlebox

\usepackage{arabtex}
\usepackage{amssymb}
\usepackage{caption}
\usepackage{epsfig}
\usepackage{subfigure}
\usepackage{color}
\usepackage{rotate}
\usepackage{rotating}
\usepackage{amsthm}
\usepackage{booktabs}

\usepackage{relsize}
\usepackage{fancyvrb}
\usepackage[colorlinks=false]{hyperref}

\usepackage{utf8}
\setarab
\fullvocalize
\transtrue
\arabtrue


%\newcommand{\CharCodeIn}[1]{`\CodeIn{#1}'}
\newcommand{\CodeIn}[1]{{\small\texttt{#1}}}
\newcommand{\frl}[1]{\fbox{\RL{#1}}} 
\newcommand{\noArRL}[1]{\arabfalse\RL{#1}\arabtrue} 
\newcommand{\noTrRL}[1]{\transfalse\RL{#1}\transtrue}
\newcommand{\noTrnoVocRL}[1]{\transfalse\novocalize\noTrRL{#1}\vocalize\transtrue}  
\newcommand{\noVocRL}[1]{\transtrue\novocalize\RL{#1}\vocalize}  

%\title{Instructions for NAACL HLT 2010 Proceedings\Thanks{This...}}
%\title{Application-Specific Arabic Morphological Analyzer for Arabic Text Mining}% maybe add "with Enhanced Capabilities"
\title{Application-Specific Enhanced Morphological Analyzer \\for Arabic Text Mining}% maybe add "with Enhanced Capabilities"

%\author{ Jad Makhlouta \\\And
%Hamza Harkous \\
%  American University of Beirut \\
%  {\tt \{jem04, hhh20, fz11\}@aub.edu.lb } \\\And 
%  Fadi Zaraket 
%}

\date{}

\begin{document}
\maketitle
\begin{abstract}
Natural language processing (NLP) uses morphological 
analysis to abstract and annotate text.
Often times, 
%      and in particular in the context of the Arabic language, 
annotations resulting from 
a branch of morphological analysis may not be
appropriate for the case study at hand. 
In this paper we present Sarf, an application-specific morphological analyzer for Arabic. 
Sarf allows an application-specific controller to control and refine
the state of the analysis on the fly. 
It uses non-deterministic finite state Automata
to analyze a stream of text. 
%Each machine corresponds to a valid analysis. 
Sarf uses concatenative analysis based on recursive affixes 
to better preserve part of speech information.
%We automated the analysis of three books of Islamic
%narrations (hadith) using Sarf, where we
%abstracted each book into a vector of complex structures.
Our results show better efficiency
compared to current analyzers.
\end{quote}
\end{abstract}

\section{Introduction}

%Automated analysis of Arabic data sets, including texts, 
%publications, records and digital media is essential
%with the huge digital Arabic content available nowadays. 
Morphological analysis is key in current automated 
analysis techniques for Arabic text. 
%Current morphological analyzers~\cite{Sughaiyer:04}
%use concatenative analysis when
%considering the internal structure 
%of an Arabic word and
%composing it into several {\em morphemes}. 
%A morpheme can be a {\em stem}, or an {\em affix}.
%An affix can be a {\em prefix, suffix, } or an {\em infix}.
%The analysis of one word may lead to several possible
%morphological solutions.
%\vocalize
%For instance, the word \RL{'a.hmadH}~\footnote{In this document, we use the default ArabTeX transliteration style ZDMG.}
%may have two valid morphological analyses. 
%The letter \RL{'a} may be a prefix and the word means 
%``I praise him'', or 
%%The letter \RL{'a} may also be 
%part of the stem \RL{'a.hmad} (a proper noun)
%and the word means ``his Ahmad''.
%
%\novocalize
The accuracy of the solutions suffer due to inherent difficulties
of morphological analysis of the Arabic language. 
For example, it is common practice to write Arabic text
without short vowels / diacritics. 
This greatly increases the ambiguity of Arabic text.
%(maybe reduce the couple of sentences below)
Moreover, Arabic letters can have up to 
four different forms
corresponding to their position in a word, i.e, beginning,
middle, end of word and separate forms. 
This allows the phrase 
\noTrnoVocRL{il_A\nospace almdrsT}
to be visually recognizable
as two separate words \noVocRL{il_A} (to) and \noVocRL{almdrsT} (the school) 
without the need of a space in between. 
The reason is the first word \noVocRL{il_A} ends with
\noVocRL{_A} a non-connecting letter. 
These words,
referred to as ``run-on'' words~\cite{Buckwalter:04},
occur often, and greatly increase the
difficulty of tokenization.

%{\bf Sarf.~~~}
In this paper, we present Sarf~\footnote{Sarf (name modified for blind review) 
has been submitted with the paper and will be available online as an open source tool.},
 a {\em novel application-specific %efficient 
enhanced %(instead of 'efficient' to engulf both efficiency and other refinements)
morphological analyzer} that uses 
non-deterministic finite state Automata 
driven by an application-specific controller.
Each machine in Sarf takes one letter at a time as input
and represents a valid morphological analysis.
The application-specific controller prunes false positives
early in the run by making a decision at every input letter
to control the machines.
%The controller we present in Section~\ref{sec:controller}
%is an FSA. However, as we explain in Section~\ref{sec:ndfsa},
%it can be a logical entity of any type.
The controller can be an FSA or any other %logical entity 
programming entity of any type,
since Automatas may be a very complex solution for some simple applications.
  %(maybe re-word this sentence) 

%Each alive machine in Sarf takes as input one letter at a time 
%from a text stream.
In addition, to being application-specific, Sarf has introduced 
many enhancements to the field of arabic morphological analysis. 
For example,
Sarf does not assume that the word at hand is a token and
performs tokenization on the fly based on morphological correctness.
Up to our knowledge, this is the first morphological analyzer that 
handles the ``run-on'' words problem. 

Sarf uses concatenative analysis with a novel %(maybe remove novel bc authors did not feel it is much)
{\em recursive affixes} refinement,
where an affix can be a sequence of other affixes which are concatenatively compatible.
%An atomic affix $a$ is a standalone affix
%that is not the concatenation of other affixes. 
%We define an affix $f: a | a f$ to be either
%an atomic affix $a$ or an atomic affix concatenated
%with an affix. 
Sarf introduces recursive affixes in order to
better retain part of speech information and enhance the 
efficiency of affix matching. 

In addition, Sarf supports disambiguation using diacritics when they are available.
This feature, to the best of our knowledge is the first attempt to benefit from 
diacritics instead of ignoring them. Prior to Sarf, the trend was to preprocess 
the text to remove any such `unwelcomed' letter. %Nonetheless, Sarf regards them as a richness to be utilized that should not be disregarded.

%Moreover, since Sarf performs tokenization on the fly, Sarf is not just capable of solving
%the problem of ``run-on'' words, but also of handling Multiword Expressions (MWE). 
Moreover, since Sarf does not perform white-space delimited tokenization, Sarf is capable of 
handling Multiword Expressions (MWEs).
MWEs are defined in~\cite{MWE}
``as idiosyncratic interpretations
that cross word boundaries (or spaces)''. 
%By this term, we refer to frequent cases when a group of words form together a single
%item with a semantical meaning. In this paper, we focus on the example of compound names such as 
%\noVocRL{`bid alkarym}. 
%In current analyzers, this phrase is analyzed word by word and in best cases is 
%considered to contain two names, instead of being understood to be a single but compound name.  

Our focus when building Sarf, was not on improving the semantical rules and 
expanding the morphological alternatives, instead we worked on adding support 
for higher level control by the specific application utilizing the lower level 
morphological analyzer. %In other words, the application-specific controller, has 
% full control over and directs the morphological analysis of Sarf. 
% (sentence should be reworded differently, but is needed to explain why we mention 
% higher and lower accuracy hypothesis, which seems vague otherwise)
%
%We have noted that many NLP case studies need the 
%morphological analyzer to answer queries that do not need 
%high accuracy at the morphological analysis level.
%The analysis at the higher levels 
%(i.e. answering the application-specific query)
%can often compensate for 
%tolerable inaccuracy at lower morphological levels. 
%For example, if a query concerns proper names and the 
%analyzer is considering a 
%prefix that connects only to a verb,
%%the analyzer can answer without considering the 
%%rest of the word.
%we do not need to further analyze the rest of the word 
%to provide a negative answer.
%
%We find evidence to our hypothesis in~\cite{Maamouri:10}.
%%The addition of a new corpus to the Arabic Tree Bank 
%%(ATB)~\cite{Maamouri:04}
%%%required compliance with the DARPA GALE program 
%%%including several NLP tasks such as English translation 
%%%annotations and word-level alignment of Arabic and English. 
%%%The new data 
%%challenged the existing processing and 
%%annotation guidelines. 
%%This led to refining 
%%SAMA~\cite{Kulick:10} with 
%%alternative guidelines. 
%%This refinement was achieved only after the NLP 
%%task interacted with the morphological analyzer,
%%a flexibility our analyzer is designed to provide for the application-specific controller on the run. %(check if this sentence makes sense)
%It reports that a refined version of SAMA~\cite{Kulick:10} was achieved when NLP task interacted with the morphological analyzer.
%%a flexibility our analyzer is designed to provide for the application-specific controller on the run.
%In addition, 
%the work of Habash~\shortcite{Habash:06} reports that different 
%types of morphological analyses behave differently on the same %case study. 
%data set.
%The analyzers may report different solutions or 
%may present the solutions in different orders. 
%Clearly, some of 
%the presented solutions and their order of presentation may not be 
%appropriate for the %case study.
%application needs, which is an issue that Sarf tackles. % (maybe reworded)
We strongly believe that by being
an application-specific morphological analyzer that allows an application-specific 
controller to intervene at every decision to guide, use, order, and 
refine the morphological analysis, Sarf is of high utility.

%We validate our hypothesis using a case study from the Islamic 
%literature, introduced later in Section~\ref{sec:results}.
In addition to all its enhanced analysis methods, Sarf still
outperformed current morphological analyzers in terms of running time.
These results will be presented in Section~\ref{sec:results}.

We make the following key contributions: 
\begin{enumerate}
\item {\bf application-specific analysis:}  We designed and implemented
a application-specific morphological analyzer where a controller
guides the analysis. 
%\item {\bf Exhaustive analysis:} Since we have an application-specific 
%controller that can decide on the fly whether an analysis is 
%accepted or not, we can afford to keep all valid analyses modulo
%those pruned by the case controller. 
%We do that using non-deterministic FSAs. 
\item {\bf Recursive affixes:}
We refine the concatenative analysis of 
Buckwalter~\shortcite{Buckwalter:02} and define affixes
recursively. 
This allows Sarf to perform better and 
maintain compositional part of speech (POS) tags.
\item {\bf Diacritic-based Disambiguation:}
Diacritics are used to disambiguate morphological
alternatives using any existant diacritics.
\end{enumerate}

%The rest of this paper is structured as follows. In Section~\ref{sec:related}
%we compare Sarf to related work. In Section~\ref{sec:sarf}
%we discuss Sarf and illustrate it with a running example.
%%We also explain how non-deterministic finite state Automata
%%work. 
%In Section~\ref{sec:islamic} we present the case
%study. We present our results in Section~\ref{sec:results}
%and conclude with future work in Section~\ref{sec:future}.

% does not have to be a subsection, 
%just to highlight it as an item we should not miss

%\section{Background}
% TODO: nondeterministic finite-state automata

\subsection{Related work }
\label{sec:related}

The survey in~\cite{Sughaiyer:04} compares
several morphological analyzers. 
Analyzers such as~\cite{Khoja:01,Darwish:02} 
target specific applications in the 
analyzer itself or use a specific set of POS tags
as their reference.
Sarf differs in that it is a general morphological 
analyzer that reports all possible solutions. 
It is application-specific in the sense that a controller 
prunes these solutions. 

Current morphological analyzers such as %(maybe disambiguators also added here according to reviewer comments)
Buckwalter~\shortcite{Buckwalter:02},
Beesley~\shortcite{Beesley:01},
SAMA~\cite{Kulick:10},
and ElixirFM~\cite{Otakar:07} 
take as input white space delimited tokens~\cite{Kulick:10},
consider them as words,
and enumerate all possible solutions. 
%This approach has several problems. 
However, we note the following points that deserve consideration:
%(We need not to mention especially point 2 as a "problem" according to reviewer comments)
First, a white space delimited token may have 
more than one word or just a part of a MWE.
%Second, the exhaustive enumeration may hurt performance and may
%not be necessary or appropriate
%in some case studies as noted in~\cite{Maamouri:10}. 
Second, in many applications, the exhaustive enumeration may not be needed or appropriate as noted in~\cite{Maamouri:10}; consequently, adding unnecessary running time.
Other morphological analyzers such as 
Amira~\cite{Diab:07,Benajiba:07},
MAGEAD~\cite{Habash:05}, and MADA+TOKAN~\cite{Habash:09} 
% (reviewer wants to distinguish MADA as a tool for morphological disambiguation instead of analysis)
use machine learning and support vector machines (SVM) 
to enhance the accuracy of the morphological analysis at the expense 
of efficiency.
Xerox rules can be compiled into specialized finite state
machine (FSM) based analyzers as described in~\cite{Beesley:03}.
However, the efficiency of the resulting analyzer depends on the
way the Xerox rules are written. 
This requires deep knowledge and insight from the user
in compilation techniques, context free grammars, 
and morphological analysis.
%context free grammar rules that can be automatically compiled
%into efficient non-deterministic finite state Automata (NDFSA). 

Sarf builds upon the lexicon of Buckwalter\shortcite{Buckwalter:02}.
It differs from Buckwalter in that it defines a shorter list of affixes
and a longer list of affix compatibility rules to allow 
affixes to be defined recursively
so that we can have prefix-prefix an suffix-suffix 
concatenations.
This allows Sarf to better maintain and propagate 
the POS tags associated with affixes. 
%This information is highly 
%redundant with Buckwalter.% and that may lead to consistency issues. 
Sarf keeps all the possible analyses alive where each analysis
corresponds to a set of decisions and positions in the text. 
Buckwalter produces a set of solutions for each token 
and the several analysis threads of the text need to be 
generated as a product of the token solutions. 

Similar to Sarf, both Beesley~\shortcite{Beesley:01} and Attia~\shortcite{Attia:05} use
finite state Automata (FSA). 
Beesley reports that the number of Automata generated by a compiler
for Xerox rules can not be controlled and also reports a difficulty 
to compose the FSAs into a single framework. 
Sarf however constructs an NDFSA from
the controller and the prefix, stem, and suffix deterministic 
transducers to solve the problem.
Sarf also differs in that it uses recursive affixes in the 
affix transducers, and in that the transducers consider
input from the controller to modify their behavior. 
%With Sarf it is easy to control the FSA with a application-specific
%controller. 
Beesley requires recompilation of the Xerox rules. 
Attia has researched extensively MWEs handling methods~\cite{Attia:06} and 
automated extending their dictionary coverage~\cite{Attia:10}. 
% (I am not sure how clear this statement is)

Similar to The MADA+TOKAN toolkit, Sarf thinks of
the several valid morphological analyses as a richness that 
should be exploited at a higher abstract level rather than
an inaccuracy that should be corrected. 
Sarf differs in that it provides an interface for the 
application to interfere in judging the analyses much earlier and
at a finer granularity level. 
In Sarf, there is no need for a separate tokenizer such as
TOKAN since each solution keeps a stack of positions
that partition text into morphemes.
%The application-specific controller can build the trace 
%when needed. 

%MAGEAD 
%Maamouri, Mohamed and \bgroup et al.\egroup },

Our approach is close to the refinement of SAMA~\cite{Maamouri:10}.
SAMA was refined to interact with
the ATB~\cite{Maamouri:04} project after the addition of a large 
new corpus. 
%We find supporting evidence in this decision to our hypothesis
%about the utility of a application-specific analyzer. 
The algorithmic changes in SAMA were
done manually and worked in integration with the ATB format. 
Sarf is an application-specific controller approach that can modify 
the behavior of the analyzer on the fly and can interact
with any application as needed. 
In Sarf, the analyzer remains general, and the 
application-specific controller specializes the analysis.

The AMIRA~\cite{Diab:07} analyzer uses 
a language independent SVM based analysis. 
The SVM analysis learns features from the input text 
and does not make use of any information 
in the target query.

Like ElixirFM~\cite{Otakar:07}, Sarf builds on the lexicon
of the Buckwalter analyzer. 
Sarf also uses deterministic parsing with tries 
to implement the affix and stem transducers. 
We think that the inferential-realizational approach 
of ElixirFM
that is highly compatible with the Arabic linguistic 
description~\cite{Badawi:04}
can benefit from many features unique to the Arabic language.
Sarf leaves implementing that to the application-specific controller
since in many cases the abstraction needs only a partial 
linguistic model of the Arabic language. 
%We can compare the application-specific controller in Sarf to a high level
%component in the ElixirFM domain specific language. 


\section{Sarf}
\label{sec:sarf}

Sarf extends the lexicon of Buckwalter~\shortcite{Buckwalter:02} with
proper names and location names extracted from different online 
sources~\footnote{\href{http://alasmaa.net/}{http://alasmaa.net/ }, 
\href{http://ar.wikipedia.org/}{http://ar.wikipedia.org/}}
as well as biblical sources~\footnote{Genesis 4:17-23; 5:1-32; 9:28-10:32; 11:10-32; 25:1-4, 12-18; 36:1-37:2; Exodus 6:14-25; Ruth 4:18-22; 1 Samuel 14:49-51; 1 Chronicles 1:1-9:44; 14:3-7; 24:1; 25:1-27:22; Nehemiah 12:8-26; Matthew 1:1-16; Luke 3:23-38}.

Sarf encodes the prefix, suffix and stem lexicons into
three deterministic transducers and 
uses a non-deterministic construction
of the three to compute all valid morphological analyses.
We first present a running example of Sarf.
The running example explains how Sarf works,
implements recursive affixes, and
handles ``run-on'' words.
%Then we discuss how Sarf builds and composes the different FSAs.

\subsection{Sarf example}
\label{sec:example}

\transfalse
\begin{figure}[tb]
\center{
\resizebox{\columnwidth}{!}
{ \input{figs/FSM.pdftex_t}}
\caption{Example affix and stem transducers.}
\label{f:example}
}
\end{figure}
% the FSMs for the three words
%\transtrue

%{\bf Sarf example.}

The diagram in Figure~\ref{f:example}
illustrates the operation of $\Phi$, the Sarf FSA,
when parsing the
string \noTrnoVocRL{wsyl`b-h-aa\nospace al-lA`bwn}.
%\RL{al-lA`bwn}\RL{wsyl`b-h-aa}.
\footnote{ 
\noVocRL{n}%
\noVocRL{w}
\noVocRL{b}
\noVocRL{`}
\noVocRL{a} 
\noVocRL{l}
\noVocRL{l}
\noVocRL{a} %
\noVocRL{a}
\noVocRL{h}
\noVocRL{b}
\noVocRL{`}
\noVocRL{l}
\noVocRL{y}
\noVocRL{s}
\noVocRL{w}
in separate form to ease following the example
}

Boxes and circles denote accept and regular
states respectively.
The edges are transitions with labels corresponding to
the input letters.
The reject states are omitted for clarity and are denoted
by the absence of corresponding transitions. 

Subfigures (a), (b), and (c) in Figure~\ref{f:example}
represent ${\cal P}$ the prefix ,
${\cal S}$ the stem, and ${\cal X}$ the suffix
transducers respectively. 
The symbol $\epsilon$ represents an empty string and is 
the source of non-determinism.

We start with $\Phi$ at the root square state in 
${\cal P}$ which is an accept state. 
The $\epsilon$-edge connects ${\cal P}$
to ${\cal S}$ and transitions from any accept state
in ${\cal P}$ to the root state in ${\cal S}$.
The $\epsilon$-edge that connects ${\cal S}$ to ${\cal X}$
follows the same behavior. 

When there are two valid transitions such as \noTrnoVocRL{w} 
and $\epsilon$ in the start case, 
$\Phi$ spawns an exact copy of itself $\Psi$. 
$\Phi$ makes one transition, and $\Psi$ makes the other. 
Each of $\Phi$ and $\Psi$ represent a valid analysis so far. 
An FSA ($\Phi$ or $\Psi$) dies when it reaches a reject state.
In our example, if there were no stems that start 
with the letter \noTrnoVocRL{w}, $\Psi$ will die. 
In reality, $\Psi$ will die when the input 
is at \noTrnoVocRL{wsyl`}. 

Note that the affix transducers allow recursive 
affixes. 
For example, \noTrnoVocRL{w} will result in an accept state
that transitions to ${\cal S}$.
When \noTrnoVocRL{s} follows, we move to another accept state in 
${\cal P}$ corresponding to the prefix \noTrnoVocRL{ws}. 
The same applies to ${\cal X}$. 

Lets consider $\Phi$ after it consumed \noTrnoVocRL{wsy} 
and transitioned into the root node of ${\cal S}$.
Now $\Phi$ will transition with \noTrnoVocRL{l`b} to reach an accept 
state. 

Before moving with the letter \noTrnoVocRL{b} to the accept state,
$\Phi$ needs to make sure that the stem \noTrnoVocRL{l`b} is compatible
with the prefix \noTrnoVocRL{wsy}. 
Sarf keeps compatibility category values as part
of the accept states. 
%Sarf considers the value of the category as part of the state.
Thus each accept state in Figure~\ref{f:example} represents
more than one concrete state. 
If the category of \noTrnoVocRL{l`b} is compatible with the category of
\noTrnoVocRL{wsy} then \noTrnoVocRL{b} will move $\Phi$ to an accept state. 
Otherwise, it will move it to a regular or a reject state. 
       
Since $\Phi$ is now in an accept state in ${\cal S}$, it 
spawns $\Xi$ which transitions to the root of ${\cal X}$. 
After it consumes \noTrnoVocRL{h--} $\Phi$ dies since there is no
\noTrnoVocRL{h--}-edge from the current state.
$\Xi$ represents a valid analysis and proceeds.
       
Note that $\Xi$ reports a full word at any accept state
by spawning a new FSA using the $\epsilon$ transition
to ${\cal P}$.
In Sarf, this only happens with white space, delimiters, 
and non-connecting letters. 
We left that out in Figure~\ref{f:example} for clarity. 
       
The application-specific controller can interfere at any point in the 
analysis to make a decision like ignoring an FSA that 
is not interesting. 
It may also decide to correct one FSA
based on the decision of the others. 
The controller uses the output of the transducers as input
to make its decision. 
It does not produce external output and therefore 
the three transducers with the 
controller compose an FSA.

\subsection{Recursive affixes}
\label{sec:recaffix}

We call two morphemes compatible if their concatenation
forms a legal morpheme. 
Buckwalter~\shortcite{Buckwalter:02} keeps separate lists 
of affix and stem morphemes and assigns categories to
morphemes. 
%The relation between morphemes and categories is one 
%to many. 
A compatibility rule is a pair of categories 
$\langle c_1, c_2\rangle$  stating that $c_1$ morphemes
can be concatenated with $c_2$ morphemes.
Buckwalter keeps three lists $L_{ps}, L_{sx},$ and $L_{px}$ 
of compatibility rules relating
prefixes to stems, stems to suffixes, and prefixes to suffixes
respectively. 
Consider a string $s=\alpha\beta\gamma$ where $\alpha$ is 
a prefix, $\beta$ is a stem, and $\gamma$ is a suffix;
$\alpha\beta\gamma$ is a 
valid morphological analysis iff
$\langle c(\alpha),c(\beta)\rangle \in L_{ps}$ and
$\langle c(\beta),c(\gamma)\rangle \in L_{sx}$ and
$\langle c(\alpha),c(\gamma)\rangle \in L_{px}$, where
$c()$ returns the category of the morpheme.

Many affixes are composed of other affixes. For example,
the prefix \RL{wsy} is composed of three other prefixes
namely \RL{w}, \RL{s}, and \RL{y}.
The POS tag for \RL{wsy} is a concatenation
of the POS tags of each of the three morphemes. 
Keeping all valid morphemes in a list
is redundant and may lead to consistency issues when
users try to add their custom morphemes.
We introduce $L_{pp}$ and
$L_{xx}$ as prefix-prefix and suffix-suffix 
compatibility rules respectively.
%This allows us to keep a shorter list of affixes. 
We also introduce a {\em resulting category}
for the $L_{pp}$ and  $L_{xx}$ resulting morphemes.
%The resulting category in all practical cases
%is that of the second morpheme in the pair. 

%Sarf only keeps atomic affixes and their categories.

\subsection{Affix transducers}
\label{sec:affixFSA}

We analyzed the prefixes and suffixes of 
Buckwalter~\shortcite{Buckwalter:02}
and constructed the recursive affixes
into directed acyclic graphs (DAG) similar to 
those in Figures~\ref{f:example}(a) and~\ref{f:example}(c).
The transducers are deterministic and thus 
their traversal is linear.
This is computationally superior to the 
approach of Buckwalter where the analyzer considers
all possible substrings %of the word in question
and looks them up in the affix tables. 

The affix transducers encode $L_{pp}$ and
$L_{xx}$.
An accept state in the transducer corresponds to the last letter 
of an affix in the affix lists.
The accept states produce as output the POS and other tags
associated with the state.

\subsection{Stem transducer}
\label{sec:stemFSA}

We built our stem lexicon using the stem lexicon of 
Buckwalter. 
We augmented the lexicon with a set of proper names and
a set of location names which we 
obtained from online and biblical sources. 

The stems share lots of substrings. We encoded them in
an efficient double array trie structure~\cite{Aoe:89}. 
The structure is deterministic and free of cycles where the 
accept states are the terminal nodes corresponding to the last 
letters in stems. Note that the trie implementation may not 
necessary work on letter-by-letter states, but also compacts
common substrings.
This approach is superior to Buckwalter since it consists of
a linear walk in the trie while with Buckwalter we need
a number of hash lookups in the order of all possible partitions
of the string.

\subsection{Construction of Sarf from transducers}
\label{sec:ndfsa}

The diagram in Figure~\ref{f:composition} shows an 
abstraction of the non-deterministic construction of Sarf
from the prefix, stem and suffix transducers. 
The circle represents regular states, the square
represents accept states and the triangle represents
reject states. 
Note that the concrete prefix, stem and suffix transducers
are all deterministic and cycle free as discussed 
is Sections~\ref{sec:affixFSA} and~\ref{sec:stemFSA}.
The cycles are introduced in the abstract machine
for pedagogical purposes.

%Note that Sarf does not rely on implementing its machines as 
%equivalent regular expressions due to  the following reasons ...
% (not necessary)

\begin{figure}[tb]
\center{
\resizebox{\columnwidth}{!}
{ \input{figs/abstract_machine.pdftex_t}}
\caption{Sarf NDFSA.}
\label{f:composition}
}
\end{figure}

The algorithm \CodeIn{NDSarf} (detailed below)
takes as input a text string $L$ and a application-specific controller
$A$. 
It starts with one machine $\Phi_1$ similar to the one in 
Figure~\ref{f:composition} and inserts it into a collection
$M$. 
The algorithm reads a letter $c$ at a time from $L$
and iterates over all machines in $M$. 
For each $\Phi$ in $M$,
if $\Phi$ is in an accept state and it is in the suffix
phase, then the algorithm checks whether it should report
a full word. 
This happens when $c$ is a white space, a delimiter, 
or when the preceding letter %leading to the current state
was a non-connecting letter. 

In all cases, if $\Phi$ is in an accept state, 
it spawns another machine $\Psi$ and adds it to $M$. 
Notice that spawning a new machine requires only keeping
the state of the machine since all machines share the
structures of the three transducers.
If $c$ leads to a reject state, then $\Phi$ dies 
and we remove it from $M$. 
Otherwise, $\Phi$ transitions using the $c$ edge.
After iterating over all machines in $M$, we invoke the 
controller $A$
and grant it full access and control over
all machines in $M$. 

%The arrows in Figure~\ref{f:composition} that transition
%from prefix to stem, stem to suffix, and suffix to prefix
%require compatibility constraints for 
%the transition.

\begin{table}[tb]
%\centering
%\resizebox{.9\columnwidth}{!}{
\begin{tabular} {p{6cm}}
\begin{Verbatim}[fontsize=\relsize{-2},
frame=topline,framesep=4mm,label=\fbox{NDSarf algorithm},
commandchars=\\\{\}, codes={\catcode`$=3\catcode`_=8}]
NDSarf(string $L$, Controller $A$) 
  MachineVec $M$; -- collection of machines
  Machine $\Phi_1$;
  $M$.insert($\Phi_1$);
  foreach $c$ in $L$ \{
    foreach $\Phi$ in $M$ \{
      if ( $\Phi$.state.isAccept() ) \{
        if ($\Phi$.isSuffix())
          if ($c$.isWhite())  
            $A$.report();
          if ($\Phi$.lastChar().isNonConnecting())
            $A$.report();
        $\Psi$ = $\Phi$.clone();
        $M$.insert($\Psi$); \}

      if ( $\Phi$.isWalkable($c$) ) \{
        $\Phi$.transition($c$);
      \} else \{
        $M$.remove($\Phi$);
        $\Phi$.die();
      \} \} 
    $A$.control($M$, $c$); \}
\end{Verbatim}
\end{tabular}
%}
\label{a:ndsarf}
\end{table}

\subsection{Disambiguation using diacritics}
\label{sec:diacritics}

Many Arabic documents, especially religious texts, are fully vocalized.
Even in documents written without diacritics, we often stumble at a couple of words which are partially vocalized
to reduce the difficulty of their disambiguation by the reader. Clearly, if native readers
need the aid of short vowels, automatic morphological analyzers which are context-free should not lose this precious piece of information.
Sarf is the first in the field to support diacritic-based disambiguation. Consequently, Sarf does not confuse \RL{bon} (coffee beans) with \RL{bin} (child)
or \RL{`ilm} (science) with \RL{`lim} (knew), regardless of the specific letters which are vocalized.

The lexicon of buckwalter contains the vocalized equivalent of each entry, however makes no use of their power. 
On the other hand, in Sarf's transducers after each accept state an (optional) linear-time diacritic based equality function is run
to check if the state should be reported to the controller. Accordingly, much unnecessary ambiguity is reduced.

\subsection{Multiword Expressions}
\label{sec:MWE}

The names which have been augmented to the lexicon of Sarf contain compound names such as 
\noVocRL{`bid alkarym}. 
In current analyzers with the exception of Attia, this expression is analyzed word by word and in best cases is 
considered to contain two names, instead of being understood to be a single but compound name.
Sarf enlists such expressions in the stem transducer (with one letter being the white space) and since tokenization
is performed on the fly, such expressions are detected as one unit. These multi-word stems
can accept also some compatible affixes such as \RL{w} (and) and \RL{f-} (but).
This approach works perfectly for proper names but not for ``Syntactically-Flexible Expressions'' as noted
in ~\cite{MWE}. %MWEs that can undergoe lexical inflections for their constituent words

\section{Results}
\label{sec:results}

\begin{table}[tb]
\centering
\caption{Comparsion of Running Time}
\resizebox{0.95\columnwidth}{!}{
%\begin{tabular}{lp{.01cm}cp{.01cm}cp{.01cm}c}
\begin{tabular}{lccc}
\hline
 & Al Kafi & Al Istibsar & Ibn Hanbal \\ \cline{2-4} 
Sarf & 2.7002645 & 2.6884225 & 0.2356561 \\
Buckwalter & 3.315950 & 5.406016 & 0.5472224 \\
ElixirFM & 2.78$\times60^2$ & 2.3$\times60^2$ & 29.2$\times$60 \\
\hline
\end{tabular}
}
\normalsize
\label{t:efficeincyresults}
\end{table}

In this section we compare Sarf to existing 
morphological analyzers such as Buckwalter and ElixirFM in terms of running time.
We ran the different analyzers on
three books of Islamic narrations \RL{.hady_t} ~\cite{IbnHanbal,AlTousi,AlKulayni}
We report our results in Table~\ref{t:efficeincyresults} on the 
three hadith books.

Sarf outperforms both Buckwalter and ElixirFM in terms of 
running time. 
Buckwalter performed much better than ElixirFM in 
terms of running time, 
We think the big difference is due to the sophistication of 
the formal functional morphological analysis of ElixirFM 
and its reliance on additional annotations extracted from 
both ATB~\cite{Maamouri:04} and the Prague Arabic Dependency Treebank~\cite{Prague04}.

\section{Conclusion and Future Work}
\label{sec:future}

We presented Sarf, a novel application-specific morphological analyzer,
which supports diacritic-based disambiguation and introduces recursive affixes.
%Sarf uses non-deterministic finite state Automata with 
%concatenative analysis and recursive affixes to analyze 
%Arabic text. 
Results show that Sarf is faster than
current morphological analyzers.

In a future paper, we will present our work of using Sarf to 
parse Islamic Narrations from Prophet Muhammad commonly known commonly as hadith.
We are also working on using Sarf to automate the problems of
arabic email classification and
arabic content-based parental control.
Those use cases will benefit from the application-specific nature of Sarf.

%In the future, 
%we will try Sarf with other interesting case studies.
%We plan to complete the hadith case study 
%and automate narrator discovery and authentication in the 
%biography books. 
%%We plan to make use of the name connector and narrator
%%connector stop phrases that our case study extracted to create a 
%%learning system that can learn more names. 
%%We also plan on developing an Arabic linguistic computational model 
%%similar to that of ElixirFM~\cite{Otakar:07} but that can be 
%%explored partially based on the case study. 

%\section{Acknoledgements}
%\label{sec:acc}
%We thank the Lebanese National Council for Scientific Research (LNCSR) for funding this research.


%For reasons of uniformity, Adobe's {\bf Times Roman} font should be
%used. In \LaTeX2e{} this is accomplished by putting

%\begin{quote}
%\begin{verbatim}
%\usepackage{times}
%\usepackage{latexsym}
%\end{verbatim}
%\end{quote}
%in the preamble.

%Additionally, it is of utmost importance to specify the {\bf
%  US-Letter format} (8.5in $\times$ 11in) when formatting the paper.
%When working with {\tt dvips}, for instance, one should specify {\tt
%  -t letter}.

%{\bf Citations}: Citations within the text appear
%in parentheses as~\cite{Gusfield:97} or, if the author's name appears in
%the text itself, as Gusfield~\shortcite{Gusfield:97}. 
%Append lowercase letters to the year in cases of ambiguities.  
%Treat double authors as in~\cite{Aho:72}, but write as 
%in~\cite{Chandra:81} when more than two authors are involved. 
%Collapse multiple citations as in~\cite{Gusfield:97,Aho:72}.


%\section*{Acknowledgments}
% this will go into the regular submission

%\bibliographystyle{naaclhlt2010}
\bibliographystyle{acl}
{\small \bibliography{fzAr}}

\end{document}
